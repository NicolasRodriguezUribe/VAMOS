============================= test session starts =============================
platform win32 -- Python 3.12.3, pytest-9.0.2, pluggy-1.6.0
rootdir: C:\Users\nicor\Desktop\VAMOS
configfile: pyproject.toml
testpaths: tests
plugins: cov-7.0.0
collected 257 items

tests\engine\operators\test_crossover.py ....                            [  1%]
tests\engine\operators\test_mutation.py ....                             [  3%]
tests\engine\operators\test_repair.py ....                               [  4%]
tests\engine\test_algorithms_smoke.py ........                           [  7%]
tests\engine\test_config_shortcuts.py ..........                         [ 11%]
tests\engine\test_config_variation.py ....                               [ 13%]
tests\engine\test_crowding_archive.py .                                  [ 13%]
tests\engine\test_discrete_and_mixed_operators.py ...                    [ 14%]
tests\engine\test_genealogy_tracking.py ........                         [ 17%]
tests\engine\test_nsga2_encodings_integration.py ...                     [ 19%]
tests\engine\test_nsgaii_adaptive_ops.py F                               [ 19%]
tests\engine\test_nsgaii_genealogy.py .                                  [ 19%]
tests\engine\test_nsgaii_nondominated.py ..                              [ 20%]
tests\engine\test_nsgaiii_behavior.py ....                               [ 22%]
tests\engine\test_operator_selector.py ...                               [ 23%]
tests\engine\test_optimize_api.py F...                                   [ 24%]
tests\engine\test_optimize_failures.py ..                                [ 25%]
tests\engine\test_other_algorithms_encodings.py FF.                      [ 26%]
tests\engine\test_param_space_random.py .                                [ 27%]
tests\engine\test_quick_api.py ................                          [ 33%]
tests\engine\test_racing_improvements.py ...                             [ 34%]
tests\engine\test_real_initializers.py ..                                [ 35%]
tests\engine\test_real_mutations.py ....                                 [ 36%]
tests\engine\test_reproducibility.py .                                   [ 37%]
tests\engine\test_smoke_engine.py .                                      [ 37%]
tests\engine\test_tuning_config_space.py ...                             [ 38%]
tests\engine\test_tuning_io.py ..                                        [ 39%]
tests\engine\test_tuning_task_tuner.py ..                                [ 40%]
tests\experiment\test_benchmark_reporting.py ..                          [ 41%]
tests\experiment\test_cli_integration.py .                               [ 41%]
tests\experiment\test_cli_integration_config.py ..                       [ 42%]
tests\experiment\test_cli_runner_behaviors.py .....                      [ 44%]
tests\experiment\test_cli_smoke.py ...s                                  [ 45%]
tests\experiment\test_experiment_runner.py .                             [ 46%]
tests\experiment\test_self_check.py .                                    [ 46%]
tests\foundation\test_backends_smoke.py ..                               [ 47%]
tests\foundation\test_constraints.py ......                              [ 49%]
tests\foundation\test_constraints_dsl.py .                               [ 50%]
tests\foundation\test_constraints_handling.py F..                        [ 51%]
tests\foundation\test_data_failures.py ..                                [ 52%]
tests\foundation\test_eval_backends.py ..                                [ 52%]
tests\foundation\test_exceptions.py FFF................FF.F              [ 61%]
tests\foundation\test_experiment_context.py ................             [ 68%]
tests\foundation\test_hv_zdt.py .                                        [ 68%]
tests\foundation\test_hypervolume_fallback.py ...                        [ 69%]
tests\foundation\test_kernel_failures.py ...                             [ 70%]
tests\foundation\test_metadata.py .                                      [ 71%]
tests\foundation\test_metadata_consistency.py .                          [ 71%]
tests\foundation\test_moocore_indicators.py ..                           [ 72%]
tests\foundation\test_new_benchmarks.py ...                              [ 73%]
tests\foundation\test_optimization_result.py ...............             [ 79%]
tests\foundation\test_packaging_data.py ...                              [ 80%]
tests\foundation\test_problem_registry.py ...                            [ 81%]
tests\foundation\test_problem_zoo.py .                                   [ 82%]
tests\foundation\test_run_optimization.py ......F......                  [ 87%]
tests\foundation\test_smoke_foundation.py .                              [ 87%]
tests\integration\test_minimal_imports.py ..                             [ 88%]
tests\integration\test_public_api.py ..                                  [ 89%]
tests\ux\test_genealogy_analytics.py .                                   [ 89%]
tests\ux\test_live_viz.py F.                                             [ 90%]
tests\ux\test_mcdm.py ....                                               [ 91%]
tests\ux\test_notebooks.py s                                             [ 92%]
tests\ux\test_objective_reduction.py ....                                [ 93%]
tests\ux\test_results_loader.py .                                        [ 94%]
tests\ux\test_stats.py ....                                              [ 95%]
tests\ux\test_studio_data_dm.py ...                                      [ 96%]
tests\ux\test_tuning_viz.py ...                                          [ 98%]
tests\ux\test_visualization.py ....                                      [ 99%]
tests\ux\test_visualization_failures.py .                                [100%]

================================== FAILURES ===================================
_______________ test_nsga2_with_adaptive_operator_selector_runs _______________

    def test_nsga2_with_adaptive_operator_selector_runs():
        cfg = {
            "pop_size": 10,
            "offspring_size": 10,
            "crossover": ("sbx", {"prob": 0.9, "eta": 15.0}),
            "mutation": ("pm", {"prob": "1/n", "eta": 20.0}),
            "selection": ("tournament", {"pressure": 2}),
            "survival": "nsga2",
            "engine": "numpy",
            "adaptive_operators": {
                "enabled": True,
                "method": "ucb",
                "indicator": "hv",
                "operator_pool": [
                    {"crossover": ("sbx", {"prob": 0.9, "eta": 15.0}), "mutation": ("pm", {"prob": "1/n", "eta": 20.0})},
                    {"crossover": ("blx_alpha", {"prob": 0.9, "alpha": 0.5}), "mutation": ("gaussian", {"prob": "1/n", "sigma": 0.1})},
                ],
            },
        }
        algo = NSGAII(cfg, NumPyKernel())
        problem = DummyProblem()
        result = algo.run(problem, termination=("n_eval", 30), seed=0)
>       assert "F" in result and result["F"].shape[0] == cfg["pop_size"]
E       AssertionError: assert ('F' in {'F': array([[4.09735239e-02, 1.65276355e-02],\n       [7.95546936e-01, 0.00000000e+00],\n       [7.02275263e-01, 6.3325....95546936e-01, 0.00000000e+00],\n       [7.02275263e-01, 6.33252601e-05]]), 'evaluations': 30, 'hv_reached': False, ...} and 3 == 10)

tests\engine\test_nsgaii_adaptive_ops.py:41: AssertionError
___________________ test_optimize_explicit_algorithm_nsga2 ____________________

    def test_optimize_explicit_algorithm_nsga2():
        problem = ZDT1Problem(n_var=6)
        cfg = OptimizeConfig(
            problem=problem,
            algorithm="nsgaii",
            algorithm_config=_nsgaii_cfg(),
            termination=("n_eval", 12),
            seed=1,
            engine="numpy",
        )
        result = optimize(cfg)
        assert isinstance(result, OptimizationResult)
        assert result.F.shape[1] == problem.n_obj
>       assert result.X.shape[0] == cfg.algorithm_config.pop_size
E       AssertionError: assert 4 == 6
E        +  where 6 = NSGAIIConfigData(pop_size=6, crossover=('sbx', {'prob': 0.9, 'eta': 20.0}), mutation=('pm', {'prob': '1/n', 'eta': 20...., mutation_prob_factor=None, result_mode=None, archive_type=None, constraint_mode='feasibility', track_genealogy=False).pop_size
E        +    where NSGAIIConfigData(pop_size=6, crossover=('sbx', {'prob': 0.9, 'eta': 20.0}), mutation=('pm', {'prob': '1/n', 'eta': 20...., mutation_prob_factor=None, result_mode=None, archive_type=None, constraint_mode='feasibility', track_genealogy=False) = OptimizeConfig(problem=<vamos.foundation.problem.zdt1.ZDT1Problem object at 0x000002319E1CF7A0>, algorithm='nsgaii', a...ibility', track_genealogy=False), termination=('n_eval', 12), seed=1, engine='numpy', eval_backend=None, live_viz=None).algorithm_config

tests\engine\test_optimize_api.py:35: AssertionError
________________________ test_moead_binary_and_integer ________________________

    def test_moead_binary_and_integer():
>       _run_moead(BinaryKnapsackProblem(n_var=8), ("uniform", {"prob": 0.9}), ("bitflip", {"prob": "1/n"}))

tests\engine\test_other_algorithms_encodings.py:63: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

problem = <vamos.foundation.problem.binary.BinaryKnapsackProblem object at 0x000002319E28CB90>
cross = ('uniform', {'prob': 0.9}), mut = ('bitflip', {'prob': '1/n'})
pop_size = 12, n_eval = 60

    def _run_moead(problem, cross, mut, pop_size=12, n_eval=60):
        cfg = (
            MOEADConfig()
            .pop_size(pop_size)
            .neighbor_size(min(5, pop_size))
            .delta(0.9)
            .replace_limit(2)
            .crossover(cross[0], **cross[1])
            .mutation(mut[0], **mut[1])
            .aggregation("tchebycheff")
            .engine("numpy")
        ).fixed()
        algo = MOEAD(cfg.to_dict(), kernel=NumPyKernel())
        res = algo.run(problem, termination=("n_eval", n_eval), seed=0)
>       assert "F" in res and res["F"].shape[0] == pop_size
E       AssertionError: assert ('F' in {'F': array([[ 23.45649909, -25.37381095],\n       [ 15.59975458, -23.23426231],\n       [  5.33981139, -19.90016585],\n ...  [1, 0, 1, 0, 0, 1, 0, 1],\n       [1, 0, 1, 0, 0, 1, 0, 1]], dtype=int8), 'evaluations': 60, 'hv_reached': False, ...} and 8 == 12)

tests\engine\test_other_algorithms_encodings.py:26: AssertionError
_______________________ test_smsemoa_binary_and_integer _______________________

    def test_smsemoa_binary_and_integer():
>       _run_smsemoa(BinaryKnapsackProblem(n_var=8), ("uniform", {"prob": 0.9}), ("bitflip", {"prob": "1/n"}))

tests\engine\test_other_algorithms_encodings.py:72: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

problem = <vamos.foundation.problem.binary.BinaryKnapsackProblem object at 0x000002319E28FCB0>
cross = ('uniform', {'prob': 0.9}), mut = ('bitflip', {'prob': '1/n'})
pop_size = 10, n_eval = 40

    def _run_smsemoa(problem, cross, mut, pop_size=10, n_eval=40):
        cfg = (
            SMSEMOAConfig()
            .pop_size(pop_size)
            .crossover(cross[0], **cross[1])
            .mutation(mut[0], **mut[1])
            .selection("tournament", pressure=2)
            .reference_point(offset=0.1, adaptive=True)
            .engine("numpy")
        ).fixed()
        algo = SMSEMOA(cfg.to_dict(), kernel=NumPyKernel())
        res = algo.run(problem, termination=("n_eval", n_eval), seed=0)
>       assert "F" in res and res["F"].shape[0] == pop_size
E       AssertionError: assert ('F' in {'F': array([[  6.3052368 , -18.48683003],\n       [ 20.4725387 , -23.7705842 ],\n       [  2.40813248, -18.04988374],\n ... 1, 0, 0, 1, 1],\n       [1, 1, 0, 1, 0, 0, 0, 1],\n       [1, 1, 1, 1, 0, 1, 0, 1]], dtype=int8), 'generation': 30, ...} and 8 == 10)

tests\engine\test_other_algorithms_encodings.py:42: AssertionError
____________ test_feasibility_handling_prefers_feasible_solutions _____________

    def test_feasibility_handling_prefers_feasible_solutions():
        problem = LinearConstraintProblem()
        algo = _make_nsgaii("feasibility")
        result = algo.run(problem, termination=("n_eval", 40), seed=3)
        G = result.get("G")
        assert G is not None
        feas = is_feasible(G)
        assert feas.any()
>       assert feas.sum() >= 5  # at least half feasible in final pop
        ^^^^^^^^^^^^^^^^^^^^^^
E       assert np.int64(1) >= 5
E        +  where np.int64(1) = <built-in method sum of numpy.ndarray object at 0x00000231A12FAC70>()
E        +    where <built-in method sum of numpy.ndarray object at 0x00000231A12FAC70> = array([ True]).sum

tests\foundation\test_constraints_handling.py:51: AssertionError
_______________________ TestVAMOSError.test_basic_error _______________________

self = <test_exceptions.TestVAMOSError object at 0x000002319E11C4D0>

    def test_basic_error(self):
        """VAMOSError should work with just a message."""
>       from vamos import VAMOSError
E       ImportError: cannot import name 'VAMOSError' from 'vamos' (C:\Users\nicor\Desktop\VAMOS\src\vamos\__init__.py)

tests\foundation\test_exceptions.py:13: ImportError
__________________ TestVAMOSError.test_error_with_suggestion __________________

self = <test_exceptions.TestVAMOSError object at 0x000002319E11C2F0>

    def test_error_with_suggestion(self):
        """VAMOSError should include suggestion in message."""
>       from vamos import VAMOSError
E       ImportError: cannot import name 'VAMOSError' from 'vamos' (C:\Users\nicor\Desktop\VAMOS\src\vamos\__init__.py)

tests\foundation\test_exceptions.py:22: ImportError
___________________ TestVAMOSError.test_error_with_details ____________________

self = <test_exceptions.TestVAMOSError object at 0x000002319E11D790>

    def test_error_with_details(self):
        """VAMOSError should store details."""
>       from vamos import VAMOSError
E       ImportError: cannot import name 'VAMOSError' from 'vamos' (C:\Users\nicor\Desktop\VAMOS\src\vamos\__init__.py)

tests\foundation\test_exceptions.py:31: ImportError
__________ TestExceptionHierarchy.test_all_inherit_from_vamos_error ___________

self = <test_exceptions.TestExceptionHierarchy object at 0x000002319E11F440>

    def test_all_inherit_from_vamos_error(self):
        """All custom exceptions should inherit from VAMOSError."""
>       from vamos import (
            VAMOSError,
            ConfigurationError,
            InvalidAlgorithmError,
            ProblemError,
            OptimizationError,
            DataError,
            DependencyError,
        )
E       ImportError: cannot import name 'VAMOSError' from 'vamos' (C:\Users\nicor\Desktop\VAMOS\src\vamos\__init__.py)

tests\foundation\test_exceptions.py:193: ImportError
_____________ TestExceptionHierarchy.test_catch_all_vamos_errors ______________

self = <test_exceptions.TestExceptionHierarchy object at 0x000002319E11F710>

    def test_catch_all_vamos_errors(self):
        """Should be able to catch all VAMOS errors with VAMOSError."""
>       from vamos import VAMOSError, InvalidAlgorithmError
E       ImportError: cannot import name 'VAMOSError' from 'vamos' (C:\Users\nicor\Desktop\VAMOS\src\vamos\__init__.py)

tests\foundation\test_exceptions.py:212: ImportError
______________ TestExceptionUsage.test_all_exceptions_importable ______________

self = <test_exceptions.TestExceptionUsage object at 0x000002319E11FD10>

    @pytest.mark.smoke
    def test_all_exceptions_importable(self):
        """All exceptions should be importable from vamos."""
>       from vamos import (
            VAMOSError,
            ConfigurationError,
            InvalidAlgorithmError,
            InvalidEngineError,
            InvalidOperatorError,
            MissingConfigError,
            ProblemError,
            InvalidProblemError,
            ProblemDimensionError,
            BoundsError,
            OptimizationError,
            ConvergenceError,
            EvaluationError,
            ConstraintViolationError,
            DataError,
            ResultsNotFoundError,
            InvalidResultsError,
            DependencyError,
            BackendNotAvailableError,
        )
E       ImportError: cannot import name 'VAMOSError' from 'vamos' (C:\Users\nicor\Desktop\VAMOS\src\vamos\__init__.py)

tests\foundation\test_exceptions.py:236: ImportError
______________ TestRunOptimization.test_run_with_different_seeds ______________

self = <test_run_optimization.TestRunOptimization object at 0x000002319E168C20>

    @pytest.mark.smoke
    def test_run_with_different_seeds(self):
        """Different seeds should produce different results."""
        from vamos import run_optimization, ZDT1
    
        problem = ZDT1(n_var=10)
        result1 = run_optimization(
            problem, "nsgaii", max_evaluations=500, pop_size=20, seed=42
        )
        result2 = run_optimization(
            problem, "nsgaii", max_evaluations=500, pop_size=20, seed=123
        )
    
        # Results should differ (not exactly equal)
>       assert not np.allclose(result1.F, result2.F)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

tests\foundation\test_run_optimization.py:95: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _
.venv\Lib\site-packages\numpy\_core\numeric.py:2365: in allclose
    res = all(isclose(a, b, rtol=rtol, atol=atol, equal_nan=equal_nan))
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

a = array([[8.19788760e-01, 4.83585809e-01],
       [1.60378275e-01, 1.14011194e+00],
       [6.23825817e-02, 1.33581849e+...   [3.85199100e-01, 7.82719224e-01],
       [5.86503476e-04, 1.67055145e+00],
       [8.23606931e-01, 4.06787342e-01]])
b = array([[1.40034200e-06, 2.60877793e+00],
       [1.40034200e-06, 2.60877793e+00],
       [9.43552723e-01, 6.86885622e-...   [6.59860725e-01, 9.82497979e-01],
       [6.30339165e-01, 1.02497295e+00],
       [2.40843608e-02, 1.86381670e+00]])
rtol = 1e-05, atol = 1e-08, equal_nan = False

    @array_function_dispatch(_isclose_dispatcher)
    def isclose(a, b, rtol=1.e-5, atol=1.e-8, equal_nan=False):
        """
        Returns a boolean array where two arrays are element-wise equal within a
        tolerance.
    
        The tolerance values are positive, typically very small numbers.  The
        relative difference (`rtol` * abs(`b`)) and the absolute difference
        `atol` are added together to compare against the absolute difference
        between `a` and `b`.
    
        .. warning:: The default `atol` is not appropriate for comparing numbers
                     with magnitudes much smaller than one (see Notes).
    
        Parameters
        ----------
        a, b : array_like
            Input arrays to compare.
        rtol : array_like
            The relative tolerance parameter (see Notes).
        atol : array_like
            The absolute tolerance parameter (see Notes).
        equal_nan : bool
            Whether to compare NaN's as equal.  If True, NaN's in `a` will be
            considered equal to NaN's in `b` in the output array.
    
        Returns
        -------
        y : array_like
            Returns a boolean array of where `a` and `b` are equal within the
            given tolerance. If both `a` and `b` are scalars, returns a single
            boolean value.
    
        See Also
        --------
        allclose
        math.isclose
    
        Notes
        -----
        For finite values, isclose uses the following equation to test whether
        two floating point values are equivalent.::
    
         absolute(a - b) <= (atol + rtol * absolute(b))
    
        Unlike the built-in `math.isclose`, the above equation is not symmetric
        in `a` and `b` -- it assumes `b` is the reference value -- so that
        `isclose(a, b)` might be different from `isclose(b, a)`.
    
        The default value of `atol` is not appropriate when the reference value
        `b` has magnitude smaller than one. For example, it is unlikely that
        ``a = 1e-9`` and ``b = 2e-9`` should be considered "close", yet
        ``isclose(1e-9, 2e-9)`` is ``True`` with default settings. Be sure
        to select `atol` for the use case at hand, especially for defining the
        threshold below which a non-zero value in `a` will be considered "close"
        to a very small or zero value in `b`.
    
        `isclose` is not defined for non-numeric data types.
        :class:`bool` is considered a numeric data-type for this purpose.
    
        Examples
        --------
        >>> import numpy as np
        >>> np.isclose([1e10,1e-7], [1.00001e10,1e-8])
        array([ True, False])
    
        >>> np.isclose([1e10,1e-8], [1.00001e10,1e-9])
        array([ True, True])
    
        >>> np.isclose([1e10,1e-8], [1.0001e10,1e-9])
        array([False,  True])
    
        >>> np.isclose([1.0, np.nan], [1.0, np.nan])
        array([ True, False])
    
        >>> np.isclose([1.0, np.nan], [1.0, np.nan], equal_nan=True)
        array([ True, True])
    
        >>> np.isclose([1e-8, 1e-7], [0.0, 0.0])
        array([ True, False])
    
        >>> np.isclose([1e-100, 1e-7], [0.0, 0.0], atol=0.0)
        array([False, False])
    
        >>> np.isclose([1e-10, 1e-10], [1e-20, 0.0])
        array([ True,  True])
    
        >>> np.isclose([1e-10, 1e-10], [1e-20, 0.999999e-10], atol=0.0)
        array([False,  True])
    
        """
        # Turn all but python scalars into arrays.
        x, y, atol, rtol = (
            a if isinstance(a, (int, float, complex)) else asanyarray(a)
            for a in (a, b, atol, rtol))
    
        # Make sure y is an inexact type to avoid bad behavior on abs(MIN_INT).
        # This will cause casting of x later. Also, make sure to allow subclasses
        # (e.g., for numpy.ma).
        # NOTE: We explicitly allow timedelta, which used to work. This could
        #       possibly be deprecated. See also gh-18286.
        #       timedelta works if `atol` is an integer or also a timedelta.
        #       Although, the default tolerances are unlikely to be useful
        if (dtype := getattr(y, "dtype", None)) is not None and dtype.kind != "m":
            dt = multiarray.result_type(y, 1.)
            y = asanyarray(y, dtype=dt)
        elif isinstance(y, int):
            y = float(y)
    
        # atol and rtol can be arrays
        if not (np.all(np.isfinite(atol)) and np.all(np.isfinite(rtol))):
            err_s = np.geterr()["invalid"]
            err_msg = f"One of rtol or atol is not valid, atol: {atol}, rtol: {rtol}"
    
            if err_s == "warn":
                warnings.warn(err_msg, RuntimeWarning, stacklevel=2)
            elif err_s == "raise":
                raise FloatingPointError(err_msg)
            elif err_s == "print":
                print(err_msg)
    
        with errstate(invalid='ignore'):
    
>           result = (less_equal(abs(x - y), atol + rtol * abs(y))
                                     ^^^^^
                      & isfinite(y)
                      | (x == y))
E           ValueError: operands could not be broadcast together with shapes (12,2) (20,2)

.venv\Lib\site-packages\numpy\_core\numeric.py:2496: ValueError
_______________________ test_live_viz_callbacks_invoked _______________________

monkeypatch = <_pytest.monkeypatch.MonkeyPatch object at 0x00000231A14FA9F0>
tmp_path = WindowsPath('C:/Users/nicor/AppData/Local/Temp/pytest-of-nicor/pytest-8/test_live_viz_callbacks_invoke0')

    def test_live_viz_callbacks_invoked(monkeypatch, tmp_path):
        monkeypatch.setenv("MPLBACKEND", "Agg")
        cfg = (
            NSGAIIConfig()
            .pop_size(6)
            .offspring_size(6)
            .crossover("sbx", prob=0.9, eta=10.0)
            .mutation("pm", prob="1/n", eta=10.0)
            .selection("tournament", pressure=2)
            .survival("nsga2")
            .engine("numpy")
            .fixed()
        )
        algo = NSGAII(cfg.to_dict(), kernel=NumPyKernel())
        problem = DummyProblem()
        recorder = RecorderViz()
    
        result = algo.run(problem, termination=("n_eval", 12), seed=1, live_viz=recorder)
    
>       assert result["F"].shape[0] == cfg.pop_size
E       AssertionError: assert 2 == 6
E        +  where 6 = NSGAIIConfigData(pop_size=6, crossover=('sbx', {'prob': 0.9, 'eta': 10.0}), mutation=('pm', {'prob': '1/n', 'eta': 10...., mutation_prob_factor=None, result_mode=None, archive_type=None, constraint_mode='feasibility', track_genealogy=False).pop_size

tests\ux\test_live_viz.py:61: AssertionError
============================== warnings summary ===============================
tests/ux/test_live_viz.py::test_live_pareto_plot_saves_file
  C:\Users\nicor\Desktop\VAMOS\src\vamos\ux\visualization\live_viz.py:149: UserWarning: FigureCanvasAgg is non-interactive, and thus cannot be shown
    self.plt.pause(0.01)

-- Docs: https://docs.pytest.org/en/stable/how-to/capture-warnings.html
=========================== short test summary info ===========================
FAILED tests/engine/test_nsgaii_adaptive_ops.py::test_nsga2_with_adaptive_operator_selector_runs
FAILED tests/engine/test_optimize_api.py::test_optimize_explicit_algorithm_nsga2
FAILED tests/engine/test_other_algorithms_encodings.py::test_moead_binary_and_integer
FAILED tests/engine/test_other_algorithms_encodings.py::test_smsemoa_binary_and_integer
FAILED tests/foundation/test_constraints_handling.py::test_feasibility_handling_prefers_feasible_solutions
FAILED tests/foundation/test_exceptions.py::TestVAMOSError::test_basic_error
FAILED tests/foundation/test_exceptions.py::TestVAMOSError::test_error_with_suggestion
FAILED tests/foundation/test_exceptions.py::TestVAMOSError::test_error_with_details
FAILED tests/foundation/test_exceptions.py::TestExceptionHierarchy::test_all_inherit_from_vamos_error
FAILED tests/foundation/test_exceptions.py::TestExceptionHierarchy::test_catch_all_vamos_errors
FAILED tests/foundation/test_exceptions.py::TestExceptionUsage::test_all_exceptions_importable
FAILED tests/foundation/test_run_optimization.py::TestRunOptimization::test_run_with_different_seeds
FAILED tests/ux/test_live_viz.py::test_live_viz_callbacks_invoked - Assertion...
============ 13 failed, 242 passed, 2 skipped, 1 warning in 11.96s ============
