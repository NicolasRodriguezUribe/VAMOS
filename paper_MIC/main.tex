\documentclass[runningheads]{llncs}

\usepackage{graphicx}
\usepackage{booktabs}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage[protrusion=true,expansion=false]{microtype}
\usepackage{algorithm}
\usepackage{algpseudocode}
\usepackage{hyperref}

\hypersetup{
  colorlinks=true,
  linkcolor=blue,
  citecolor=blue,
  urlcolor=blue
}

\newcommand{\VAMOS}{VAMOS}

% Auto-generated experiment summary macros (safe placeholder if not generated yet)
\input{tables/summary_macros}

\begin{document}

\title{Adaptive Operator Selection for NSGA-II in a Vectorized Framework}
\titlerunning{Adaptive Operator Selection for NSGA-II}

\author{Nicol\'{a}s R. Uribe\inst{1} \and Alberto Herr\'{a}n\inst{1}\thanks{Corresponding author: Alberto Herr\'{a}n (alberto.herran@urjc.es)} \and Antonio J. Nebro\inst{2,3} \and J. Manuel Colmenar\inst{1}}
\authorrunning{Uribe et al.}

\institute{Dept. Computer Sciences, Universidad Rey Juan Carlos\\
C/. Tulip\'{a}n, s/n, M\'{o}stoles, 28933 (Madrid), Spain\\
\email{nicolas.rodriguez@urjc.es, alberto.herran@urjc.es, josemanuel.colmenar@urjc.es}
\and
Dept. de Lenguajes y Ciencias de la Computaci\'{o}n, ITIS Software, University of M\'{a}laga,\\
ETSI Inform\'{a}tica, Campus de Teatinos, 29071 (M\'{a}laga), Spain\\
\email{ajnebro@uma.es}
\and
ITIS Software, Ada Byron Research Building, C/. Arquitecto Francisco Pe\~nalosa, 18, University of M\'{a}laga, 29071 (M\'{a}laga), Spain\\
\email{ajnebro@uma.es}}

\maketitle

\begin{abstract}
Operator choice can strongly affect the performance of multiobjective evolutionary algorithms, yet the best operator may vary across problems and across stages of search.
We present an adaptive operator selection (AOS) layer for NSGA-II that treats each (crossover, mutation) pipeline as a bandit arm and selects one arm per generation, updating an online policy using survival and diversity-based rewards.
We evaluate on \AOSNProblems{} real-world engineering surrogates from the Tanabe--Ishibuchi RE and Zapotecas-Mart\'{i}nez RWA benchmark suites, spanning 2--9 objectives.
A three-way comparison (fixed operator vs.\ random arm selection vs.\ AOS) with \AOSNSeeds{} seeds shows that AOS matches or exceeds the fixed baseline on \AOSWins{} of \AOSNProblems{} problems, while significantly outperforming random arm selection (median normalized HV \AOSHVMedianAOS{} vs.\ \AOSHVMedianRandom{}).
Comparing the random arm with the baseline isolates the benefit of operator diversity; comparing AOS with the random arm isolates the benefit of intelligent selection.
AOS incurs a median runtime overhead of \AOSRuntimeOverheadPct{}\%.
\keywords{Adaptive operator selection \and Multi-armed bandits \and NSGA-II \and Multiobjective optimization \and Real-world optimization}
\end{abstract}

\input{sections/01_introduction}
\input{sections/02_background}
\input{sections/03_method}
\input{sections/04_implementation}
\input{sections/05_experiments}
\input{sections/06_results}
\input{sections/07_discussion}
\input{sections/08_threats}
\input{sections/09_conclusion}

\appendix
\renewcommand{\theHsection}{app.\Alph{section}}
\input{sections/10_appendix}

\bibliographystyle{splncs04}
\bibliography{references}

\end{document}
