\section{Discussion}
\label{sec:discussion}

The results demonstrate that AOS provides dramatic performance gains on challenging landscapes where no single operator dominates.
We now analyze the mechanisms behind the wins, the losses, and the relative contributions of portfolio diversity vs.\ intelligent selection.

\paragraph{Portfolio diversity is the primary driver.}
The most striking finding is that the \emph{random arm}---which selects operators uniformly at random---performs nearly as well as AOS overall (mean HV \AOSHVMeanRandom{} vs.\ \AOSHVMeanAOS{}).
Both dramatically outperform the fixed baseline (\AOSHVMeanBaseline{}).
This reveals that the 5-arm portfolio itself---with its combination of SBX $\eta$ variants, BLX-$\alpha$, and DE/rand/1/bin---is the main source of improvement.
On problems where the default SBX ($\eta{=}20$) fails, having \emph{any} mechanism that sometimes deploys alternative operators provides a large benefit.
This is especially pronounced on LSMOP problems, where the 100-variable search space overwhelms a single crossover strategy.

\paragraph{Where Thompson Sampling adds value.}
While portfolio diversity accounts for the bulk of the gain, Thompson Sampling contributes measurably on specific problem types.
On the bi-objective UF problems (UF1--UF7), AOS consistently outperforms the random arm (mean HV 0.755 vs.\ 0.751 for random), with the largest margins on UF7 (+1.8\%) and UF3 (+1.3\%).
On these problems, the curved Pareto sets create a dynamic landscape where different operators are optimal at different stages of search; Thompson Sampling captures this non-stationarity better than uniform random selection.
On LSMOP problems, the random arm slightly outperforms AOS on several instances (e.g., LSMOP1, LSMOP8), suggesting that the high dimensionality creates a more stationary reward signal where the overhead of Thompson Sampling's exploration phase does not pay off within the 100K-evaluation budget.

\paragraph{The tri-objective UF losses.}
AOS loses to the baseline on 3 of \AOSNProblems{} problems: UF8, UF9, and UF10 (all tri-objective).
These problems have a spherical Pareto front where the baseline's SBX ($\eta{=}20$) is well-suited.
The curved Pareto \emph{sets} of UF problems only strongly penalize single operators when the decision-space structure is bi-objective and highly non-linear; in the tri-objective case, the additional degree of freedom reduces the sensitivity to operator choice.
Notably, the random arm also loses on these problems, confirming that the deficit is not a failure of Thompson Sampling but an inherent cost of maintaining a diverse portfolio on landscapes where the default operator is already effective.

\paragraph{Intractable LSMOP problems.}
Four LSMOP problems (3, 6, 7, 9) yield zero HV for all methods, including AOS.
These problems use Rastrigin, Rosenbrock, Ackley, or Griewank distance functions that create massive numbers of local optima in 100 dimensions.
At 100{,}000 evaluations (1{,}000 generations with population size 100), no method converges to solutions within the reference front.
This represents a genuine limitation of the evaluation budget rather than a failure of AOS.
The remaining LSMOP problems (1, 2, 4, 5, 8), which use sphere or less deceptive distance functions, show consistent and often dramatic AOS advantages.

\paragraph{The accelerating convergence pattern.}
Unlike on simpler benchmarks, where convergence advantages typically narrow over time as all methods approach the Pareto front, the AOS advantage on these challenging benchmarks \emph{grows} over time (from +8\% at 5K to +23\% at 100K evaluations).
This occurs because on hard landscapes, the fixed baseline progresses slowly throughout the entire budget, while the diverse portfolio continues discovering new productive regions.
In practical terms, this means AOS is most valuable precisely when it is needed most: on difficult problems where the default operator stalls.

\paragraph{Practical implications.}
Our results suggest two complementary practical guidelines:
\begin{enumerate}
  \item \textbf{Portfolio diversity is essential} for problems with unknown landscape geometry, high dimensionality, or curved Pareto sets. Even random operator switching provides large gains over a fixed operator on such problems.
  \item \textbf{Thompson Sampling provides a safe, principled default} for operator selection. It matches or exceeds random switching on almost all problems, adds measurable value on problems with dynamic operator preferences (UF family), and never catastrophically degrades performance.
\end{enumerate}
For practitioners who know their landscape favors SBX with a specific $\eta$ (e.g., spherical tri-objective fronts), the fixed operator remains a valid choice; otherwise, an AOS layer with a diverse portfolio provides automatic adaptation with a strongly favorable risk--reward profile.
