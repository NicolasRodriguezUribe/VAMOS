\section{Implementation and reproducibility}
\label{sec:implementation}

\subsection{Integration into NSGA-II}
The AOS layer is implemented as a controller that coordinates (i) a portfolio of named arms and (ii) a bandit policy.
At the beginning of each generation, the controller selects an arm index and the algorithm uses the corresponding variation pipeline for all offspring of that generation.
During the generation, the controller records the number of offspring created by the selected arm.
After survivor selection, it computes reward components ($r_{\mathrm{surv}}$, $r_{\mathrm{nd}}$, and optionally $r_{\mathrm{hv}}$), updates the policy, and emits a trace row for logging.

\subsection{Determinism}
To support reproducibility, we separate (a) the global run seed that drives variation and selection randomness from (b) an optional policy RNG seed that drives the stochastic policy components (e.g., $\varepsilon$-greedy exploration).
With fixed seeds, the operator-selection sequence and rewards are deterministic for a given configuration.

\subsection{Logging}
We log two types of artifacts for analysis:
(i) a per-generation trace (selected operator, reward breakdown, and batch size), and
(ii) a summary table (number of pulls and mean reward per arm).
These logs support post-hoc analysis of operator switching and help diagnose when a policy locks into a single arm early.

