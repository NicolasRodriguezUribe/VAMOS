{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Fitness Landscape Analysis\n",
                "\n",
                "Understanding the **fitness landscape** is crucial for selecting the right optimization algorithm and tuning strategies. \n",
                "This notebook explores the ruggedness and structure of the TSP instances using two key techniques:\n",
                "1.  **Random Walk Autocorrelation**: Measures how correlated neighboring solutions are (ruggedness).\n",
                "2.  **Fitness-Distance Correlation (FDC)**: Measures how well fitness guides the search towards the global optimum.\n",
                "3.  **Basin of Attraction Estimation**: Estimates the number and relative size of local optima basins."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import numpy as np\n",
                "import pandas as pd\n",
                "import matplotlib.pyplot as plt\n",
                "import seaborn as sns\n",
                "from tqdm import tqdm\n",
                "\n",
                "# VAMOS imports\n",
                "from vamos.foundation.problem.tsp import TSPProblem"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 1. Load Problem\n",
                "We use the VAMOS `TSPProblem` class to load a TSPLIB instance (e.g., `kroA100`)."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Load kroA100 (100 cities)\n",
                "problem = TSPProblem(dataset=\"kroa100\")\n",
                "print(f\"Loaded {problem.labels[-1]} ({problem.n_var} cities)\")\n",
                "\n",
                "# Helper to evaluate a single solution's tour length (Objective 0)\n",
                "def eval_fitness(perm):\n",
                "    # wrapper for vectorized evaluate\n",
                "    X = np.array([perm])\n",
                "    out = {\"F\": np.zeros((1, 2))}\n",
                "    problem.evaluate(X, out)\n",
                "    return out[\"F\"][0, 0] # Return total distance"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 2. Random Walk Analysis (Ruggedness)\n",
                "We perform a random walk by iteratively applying a random 2-opt Swap (inverting a subsegment) or simpler Swap mutation.\n",
                "Since TSP neighborhoods are often defined by 2-opt (inversion) or Swap (exchange), we'll use **Swap** for simplicity in the random walk.\n",
                "\n",
                "The **Autocorrelation Function (ACF)** $\\rho(k)$ measures the correlation between fitnesses $k$ steps apart.\n",
                "- **High $\\lambda$ (Correlation Length)** implies a smooth landscape (easy).\n",
                "- **Low $\\lambda$** implies a rugged/random landscape (hard)."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def random_walk(problem, steps=1000):\n",
                "    n = problem.n_var\n",
                "    current_perm = np.random.permutation(n)\n",
                "    fitness_history = []\n",
                "    \n",
                "    current_fitness = eval_fitness(current_perm)\n",
                "    fitness_history.append(current_fitness)\n",
                "    \n",
                "    for _ in range(steps):\n",
                "        # Random Swap Mutation\n",
                "        idx = np.random.choice(n, 2, replace=False)\n",
                "        i, j = idx[0], idx[1]\n",
                "        \n",
                "        # Create neighbor\n",
                "        neighbor = current_perm.copy()\n",
                "        neighbor[i], neighbor[j] = neighbor[j], neighbor[i]\n",
                "        \n",
                "        # Evaluate (In a pure random walk, we always accept)\n",
                "        # Note: Ideally we update efficiently, but full eval is fast enough for 100 cities\n",
                "        f_new = eval_fitness(neighbor)\n",
                "        \n",
                "        current_perm = neighbor\n",
                "        current_fitness = f_new\n",
                "        fitness_history.append(current_fitness)\n",
                "        \n",
                "    return np.array(fitness_history)\n",
                "\n",
                "steps = 5000\n",
                "walk_data = random_walk(problem, steps=steps)\n",
                "\n",
                "plt.figure(figsize=(10, 4))\n",
                "plt.plot(walk_data, lw=0.5)\n",
                "plt.title(\"Random Walk Fitness Trace\")\n",
                "plt.ylabel(\"Tour Length\")\n",
                "plt.xlabel(\"Step\")\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def autocorrelation(series, k):\n",
                "    mean = np.mean(series)\n",
                "    var = np.var(series)\n",
                "    n = len(series)\n",
                "    \n",
                "    numerator = np.sum((series[:n-k] - mean) * (series[k:] - mean))\n",
                "    denominator = var * (n - k)\n",
                "    \n",
                "    return numerator / denominator if denominator != 0 else 0\n",
                "\n",
                "lags = np.arange(0, 100, 1)\n",
                "acf_vals = [autocorrelation(walk_data, l) for l in lags]\n",
                "\n",
                "plt.figure(figsize=(8, 5))\n",
                "plt.plot(lags, acf_vals, marker='o', markersize=3)\n",
                "plt.axhline(0, color='k', linestyle='--', linewidth=0.5)\n",
                "plt.title(\"Autocorrelation Function (ACF)\")\n",
                "plt.xlabel(\"Lag k\")\n",
                "plt.ylabel(\"Autocorrelation $\\rho(k)$\")\n",
                "plt.grid(True, alpha=0.3)\n",
                "plt.show()\n",
                "\n",
                "# Correlation Length: roughly where ACF drops to 1/e (~0.37)\n",
                "correlation_len = np.argmax(np.array(acf_vals) < 0.37)\n",
                "print(f\"Correlation Length ($1/e$): ~{correlation_len} steps\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 3. Fitness-Distance Correlation (FDC)\n",
                "Does fitness correlate with distance to the global optimum?\n",
                "\n",
                "Since we don't have the proven global optimum handy, we will approximate it by finding the **best solution from a large random sample** (or a quick local search run)."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def edge_distance(p1, p2):\n",
                "    # Count common edges\n",
                "    # Edges are defined by pairs (u, v)\n",
                "    def get_edges(p):\n",
                "        n = len(p)\n",
                "        edges = set()\n",
                "        for i in range(n):\n",
                "            u, v = p[i], p[(i+1)%n]\n",
                "            if u > v: u, v = v, u\n",
                "            edges.add((u, v))\n",
                "        return edges\n",
                "    \n",
                "    e1 = get_edges(p1)\n",
                "    e2 = get_edges(p2)\n",
                "    \n",
                "    # Distance = Total Edges - Common Edges\n",
                "    # Normalized to [0, n]\n",
                "    return len(e1) - len(e1.intersection(e2))\n",
                "\n",
                "# 1. Generate Samples\n",
                "pop_size = 500\n",
                "X_pop = np.array([np.random.permutation(problem.n_var) for _ in range(pop_size)])\n",
                "\n",
                "# 2. Evaluate Loop\n",
                "fitnesses = []\n",
                "out = {\"F\": np.zeros((1, 2))}\n",
                "for i in range(pop_size):\n",
                "    problem.evaluate(X_pop[i:i+1], out)\n",
                "    fitnesses.append(out[\"F\"][0, 0])\n",
                "fitnesses = np.array(fitnesses)\n",
                "\n",
                "# 3. Identify Target (Best found)\n",
                "best_idx = np.argmin(fitnesses)\n",
                "best_sol = X_pop[best_idx]\n",
                "best_fit = fitnesses[best_idx]\n",
                "\n",
                "print(f\"Best found in random sample: {best_fit:.2f}\")\n",
                "\n",
                "# 4. Compute Distances to Best\n",
                "distances = [edge_distance(p, best_sol) for p in X_pop]\n",
                "\n",
                "# 5. Plot FDC\n",
                "plt.figure(figsize=(8, 6))\n",
                "sns.regplot(x=distances, y=fitnesses, scatter_kws={'alpha':0.5, 's':10}, line_kws={'color':'red'})\n",
                "plt.title(\"Fitness-Distance Correlation (FDC)\")\n",
                "plt.xlabel(\"Edge Distance to Best Solution\")\n",
                "plt.ylabel(\"Fitness (Length)\")\n",
                "plt.show()\n",
                "\n",
                "# Calculate Pearson correlation\n",
                "r_fdc = np.corrcoef(distances, fitnesses)[0, 1]\n",
                "print(f\"FDC Coefficient r = {r_fdc:.4f}\")\n",
                "if r_fdc > 0.15:\n",
                "    print(\"Positive correlation: The problem might be deceptive (fitness leads away from optima) or unstructured relative to this reference.\")\n",
                "elif r_fdc < -0.15:\n",
                "    print(\"Negative correlation: Good sign! Better fitness implies closer to optimum.\")\n",
                "else:\n",
                "    print(\"Low correlation: The landscape is difficult/neutral.\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 4. Basin of Attraction Estimation\n",
                "We estimate number of basins by running multiple simple hill-climbers (Randomized 2-opt) from random starts."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def simple_hill_climber(problem, max_evals=1000):\n",
                "    \"\"\"Randomized 2-opt hill climber.\"\"\"\n",
                "    n = problem.n_var\n",
                "    # Start random\n",
                "    current_perm = np.random.permutation(n)\n",
                "    current_fit = eval_fitness(current_perm)\n",
                "    \n",
                "    evals = 1\n",
                "    improved = True\n",
                "    \n",
                "    while improved and evals < max_evals:\n",
                "        improved = False\n",
                "        # Try stochastic neighbors\n",
                "        for _ in range(50): \n",
                "            idx = np.random.choice(n, 2, replace=False)\n",
                "            i, j = idx[0], idx[1]\n",
                "            if i > j: i, j = j, i\n",
                "            \n",
                "            # 2-opt inversion\n",
                "            neighbor = current_perm.copy()\n",
                "            neighbor[i:j+1] = neighbor[i:j+1][::-1]\n",
                "            \n",
                "            # Greedy accept\n",
                "            f_new = eval_fitness(neighbor)\n",
                "            evals += 1\n",
                "            \n",
                "            if f_new < current_fit:\n",
                "                current_perm = neighbor\n",
                "                current_fit = f_new\n",
                "                improved = True\n",
                "                break # First improvement\n",
                "                \n",
                "    return current_fit, current_perm\n",
                "\n",
                "n_starts = 50\n",
                "print(f\"Running {n_starts} hill-climbers to sample basins...\")\n",
                "final_fitnesses = []\n",
                "\n",
                "for _ in tqdm(range(n_starts)):\n",
                "    f, _ = simple_hill_climber(problem, max_evals=1000)\n",
                "    final_fitnesses.append(f)\n",
                "\n",
                "# Group by fitness (proxy for basin identity)\n",
                "final_fitnesses = np.array(final_fitnesses)\n",
                "unique_fits, counts = np.unique(final_fitnesses, return_counts=True)\n",
                "\n",
                "# Sort by basin size\n",
                "sorted_indices = np.argsort(-counts)\n",
                "unique_fits = unique_fits[sorted_indices]\n",
                "counts = counts[sorted_indices]\n",
                "\n",
                "print(f\"Found {len(unique_fits)} distinct local optima (by fitness).\")\n",
                "\n",
                "plt.figure(figsize=(10, 5))\n",
                "plt.bar(range(len(counts)), counts, color='teal', alpha=0.7)\n",
                "plt.title(\"Basin of Attraction Sizes (Estimated by Random Starts)\")\n",
                "plt.xlabel(\"Basin ID (Sorted by Size)\")\n",
                "plt.ylabel(\"Frequency of Convergence\")\n",
                "plt.grid(axis='y', alpha=0.3)\n",
                "plt.show()\n",
                "\n",
                "if len(counts) > 0 and counts[0] > 1:\n",
                "    print(f\"Largest basin captured {counts[0]/n_starts*100:.1f}% of runs.\")\n",
                "else:\n",
                "    print(\"Landscape appears very rugged (multimodal), almost every run found a unique local optimum.\")"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.10.0"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 2
}