{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scaling Analysis: Runtime vs. Problem Size\n",
    "\n",
    "This notebook empirically measures how algorithm performance scales with problem size ($N$).\n",
    "We use the **TSP** problem and **NSGA-II** algorithm as a case study.\n",
    "\n",
    "## Goals\n",
    "1.  Measure runtime for a fixed number of evaluations as $N$ increases.\n",
    "2.  Fit a complexity curve ($O(N)$, $O(N^2)$) to the data.\n",
    "3.  (Optional) discuss theoretical parallel speedups.\n",
    "4.  **NEW**: Measure **Convergence Scaling** (Evaluations to target quality vs $N$)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy.optimize import curve_fit\n",
    "\n",
    "# VAMOS imports\n",
    "from vamos import optimize\n",
    "from vamos.algorithms import NSGAIIConfig\n",
    "from vamos.problems import TSP\n",
    "from vamos import make_problem_selection\n",
    "from vamos.foundation.metrics.hypervolume import compute_hypervolume"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Experiment Setup\n",
    "We define a function to run a quick benchmark for a given number of cities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def benchmark_tsp_scaling(n_cities_list, n_evals=1000, pop_size=100):\n",
    "    results = []\n",
    "\n",
    "    print(f\"Benchmarking NSGA-II (Pop={pop_size}, Evals={n_evals}) on TSP scaling...\")\n",
    "\n",
    "    for n_cities in n_cities_list:\n",
    "        # Create random TSP instance on a circle (predictable structure)\n",
    "        problem = TSP(n_cities=n_cities)\n",
    "\n",
    "        # Configure NSGA-II\n",
    "        algo_config = (\n",
    "            NSGAIIConfig.builder()\n",
    "            .pop_size(pop_size)\n",
    "            .crossover(\"pmx\", prob=0.9)\n",
    "            .mutation(\"swap\", prob=0.1)\n",
    "              # Ensure we test the NumPy path\n",
    "            .build()\n",
    "        )\n",
    "\n",
    "        # Measure Time\n",
    "        start_time = time.time()\n",
    "        optimize(\n",
    "            problem=problem, algorithm=\"nsgaii\", algorithm_config=algo_config, termination=(\"n_eval\", n_evals), seed=42\n",
    "        )\n",
    "        duration = time.time() - start_time\n",
    "\n",
    "        print(f\"N={n_cities}: {duration:.4f}s\")\n",
    "        results.append({\"N\": n_cities, \"Time\": duration})\n",
    "\n",
    "    return pd.DataFrame(results)\n",
    "\n",
    "\n",
    "# Define range of N\n",
    "# We go up to 200 for interactivity. Increase to 500+ for serious checks.\n",
    "n_range = [20, 40, 60, 80, 100, 150, 200, 300]\n",
    "df_res = benchmark_tsp_scaling(n_range, n_evals=2000, pop_size=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Visualize Scaling & Curve Fitting\n",
    "We fit a polynomial $T(N) = a N^2 + b N + c$ (since non-dominated sort is usually $O(M N^2)$ or $O(N^2)$ depending on implementation, and distance matrix calc for TSP is $O(N^2)$).\n",
    "Wait, for TSP, the genome length is $N$. \n",
    "- Variation operators are typically $O(N)$.\n",
    "- Evaluation (tour length) is $O(N)$.\n",
    "- So overall per-generation cost should be roughly linear $O(N)$ * Population, unless DOMINATION sort dominates.\n",
    "- Let's see empirically."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def quad_func(x, a, b, c):\n",
    "    return a * x**2 + b * x + c\n",
    "\n",
    "\n",
    "def lin_func(x, a, b):\n",
    "    return a * x + b\n",
    "\n",
    "\n",
    "x_data = df_res[\"N\"].values\n",
    "y_data = df_res[\"Time\"].values\n",
    "\n",
    "# Fit\n",
    "popt_q, _ = curve_fit(quad_func, x_data, y_data)\n",
    "popt_l, _ = curve_fit(lin_func, x_data, y_data)\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.scatterplot(data=df_res, x=\"N\", y=\"Time\", s=100, label=\"Observed\")\n",
    "\n",
    "x_plot = np.linspace(min(x_data), max(x_data), 100)\n",
    "plt.plot(x_plot, quad_func(x_plot, *popt_q), \"r--\", label=f\"Quadratic Fit ($N^2$)\")\n",
    "plt.plot(x_plot, lin_func(x_plot, *popt_l), \"g:\", label=f\"Linear Fit ($N$)\")\n",
    "\n",
    "plt.title(\"Runtime Scaling vs Problem Size (TSP + NSGA-II)\")\n",
    "plt.xlabel(\"Number of Cities (N)\")\n",
    "plt.ylabel(\"Runtime (s)\")\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Theoretical Parallel Speedup\n",
    "Assuming evaluating the population takes a fraction $P$ of the total time (typically high for complex simulations, lower for simple TSP).\n",
    "Amdahl's Law: $S(n) = \\frac{1}{(1-P) + \\frac{P}{n}}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_amdahl(p_parallel_fractions=[0.5, 0.75, 0.9, 0.99]):\n",
    "    cores = np.arange(1, 33)\n",
    "    plt.figure(figsize=(10, 6))\n",
    "\n",
    "    for p in p_parallel_fractions:\n",
    "        speedup = 1 / ((1 - p) + (p / cores))\n",
    "        plt.plot(cores, speedup, label=f\"P={p * 100:.0f}% Parallelizable\")\n",
    "\n",
    "    plt.plot(cores, cores, \"k--\", alpha=0.3, label=\"Ideal Linear Speedup\")\n",
    "    plt.title(\"Theoretical Amdahl's Law Speedup\")\n",
    "    plt.xlabel(\"Number of Cores\")\n",
    "    plt.ylabel(\"Speedup Factor\")\n",
    "    plt.legend()\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "plot_amdahl()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 4. Convergence Scaling: Search Difficulty vs Problem Size\n",
    "\n",
    "The previous sections measure **implementation speed** (how fast the code runs).\n",
    "This section measures **algorithmic efficiency** (how many evaluations to find a good solution).\n",
    "\n",
    "We ask: *\"How many evaluations does NSGA-II need to reach 95% of the best-achievable Hypervolume?\"* as problem size $N$ increases.\n",
    "\n",
    "**Setup**: We use **ZDT1** (continuous, scalable in $N_{var}$) for this analysis since it has a known optimal HV."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from vamos.problems import ZDT1\n",
    "\n",
    "\n",
    "def run_with_hv_tracking(n_var, max_evals=10000, pop_size=56, offspring_size=14, seed=42):\n",
    "    \"\"\"\n",
    "    Run NSGA-II on ZDT1 and track HV after each generation.\n",
    "    Returns a list of (eval_count, hv) tuples.\n",
    "    \"\"\"\n",
    "    problem = ZDT1(n_var=n_var)\n",
    "    ref_point = np.array([1.1, 1.1])\n",
    "\n",
    "    hv_history = []\n",
    "\n",
    "    # We simulate generations by running with increasing budgets\n",
    "    # A more elegant approach would use a callback, but this works for a notebook demo.\n",
    "    gen_size = offspring_size\n",
    "    for budget in range(gen_size, max_evals + 1, gen_size):\n",
    "        cfg = (\n",
    "            NSGAIIConfig.builder()\n",
    "            .pop_size(pop_size)\n",
    "            .offspring_size(offspring_size)\n",
    "            .crossover(\"blx_alpha\", prob=0.88, alpha=0.94, repair=\"clip\")\n",
    "            .mutation(\"non_uniform\", prob=\"0.45/n\", perturbation=0.3)\n",
    "            .selection(\"tournament\", pressure=9)\n",
    "            .repair(\"round\")\n",
    "            .archive(size=56).archive_type(\"hypervolume\")\n",
    "            \n",
    "            .build()\n",
    "        )\n",
    "        res = optimize(**dict(problem=problem, algorithm=\"nsgaii\", algorithm_config=cfg, termination=(\"n_eval\", budget), seed=seed))\n",
    "        if res.F is not None and len(res.F) > 0:\n",
    "            hv = compute_hypervolume(res.F, ref_point)\n",
    "        else:\n",
    "            hv = 0.0\n",
    "        hv_history.append((budget, hv))\n",
    "\n",
    "        # Early stop if we seem converged (HV not changing much)\n",
    "        if len(hv_history) > 3 and abs(hv_history[-1][1] - hv_history[-3][1]) < 1e-4:\n",
    "            break\n",
    "\n",
    "    return hv_history\n",
    "\n",
    "\n",
    "# Quick test\n",
    "print(\"Testing HV tracking on ZDT1 (n_var=10)...\")\n",
    "test_history = run_with_hv_tracking(n_var=10, max_evals=1000)\n",
    "print(f\"Final HV: {test_history[-1][1]:.4f} after {test_history[-1][0]} evals\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_evals_to_target(hv_history, target_fraction=0.95):\n",
    "    \"\"\"\n",
    "    Find the first evaluation count where HV >= target_fraction * final_hv.\n",
    "    \"\"\"\n",
    "    if not hv_history:\n",
    "        return np.nan\n",
    "    final_hv = hv_history[-1][1]\n",
    "    if final_hv <= 0:\n",
    "        return np.nan\n",
    "    target_hv = target_fraction * final_hv\n",
    "\n",
    "    for evals, hv in hv_history:\n",
    "        if hv >= target_hv:\n",
    "            return evals\n",
    "    return hv_history[-1][0]  # Never reached, return max\n",
    "\n",
    "\n",
    "# Run for multiple n_var values\n",
    "n_var_list = [10, 20, 30, 50]\n",
    "convergence_results = []\n",
    "\n",
    "print(\"Running Convergence Scaling Experiment...\")\n",
    "for n_var in n_var_list:\n",
    "    print(f\"  n_var={n_var}\")\n",
    "    history = run_with_hv_tracking(n_var=n_var, max_evals=5000, pop_size=50, seed=42)\n",
    "    evals_95 = find_evals_to_target(history, 0.95)\n",
    "    final_hv = history[-1][1]\n",
    "    convergence_results.append({\"n_var\": n_var, \"Evals_95\": evals_95, \"Final_HV\": final_hv})\n",
    "    print(f\"    Evals to 95%: {evals_95}, Final HV: {final_hv:.4f}\")\n",
    "\n",
    "df_conv = pd.DataFrame(convergence_results)\n",
    "df_conv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "sns.barplot(data=df_conv, x=\"n_var\", y=\"Evals_95\", palette=\"viridis\")\n",
    "plt.title(\"Convergence Scaling: Evaluations to 95% HV vs Problem Size\")\n",
    "plt.xlabel(\"Number of Decision Variables ($N_{var}$)\")\n",
    "plt.ylabel(\"Evaluations to Reach 95% of Final HV\")\n",
    "plt.grid(True, alpha=0.3, axis=\"y\")\n",
    "plt.show()\n",
    "\n",
    "# Fit a line to see if it's linear or super-linear\n",
    "try:\n",
    "    popt_conv, _ = curve_fit(lin_func, df_conv[\"n_var\"].values, df_conv[\"Evals_95\"].values)\n",
    "    print(f\"Linear Fit: Evals = {popt_conv[0]:.2f} * N + {popt_conv[1]:.2f}\")\n",
    "except:\n",
    "    print(\"Could not fit linear model.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}