{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7ad8fb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "from vamos import optimize\n",
    "from vamos.algorithms import NSGAIIConfig\n",
    "from vamos.problems import ZDT1\n",
    "from vamos.problems import DTLZ2\n",
    "from vamos.foundation.kernel.registry import KERNELS, resolve_kernel\n",
    "\n",
    "plt.style.use(\"ggplot\")\n",
    "\n",
    "\n",
    "def make_autonsgaii_config():\n",
    "    return (\n",
    "        NSGAIIConfig.builder()\n",
    "        .pop_size(56)\n",
    "        .offspring_size(14)\n",
    "        .crossover(\"blx_alpha\", prob=0.88, alpha=0.94, repair=\"clip\")\n",
    "        .mutation(\"non_uniform\", prob=\"0.45/n\", perturbation=0.3)\n",
    "        .selection(\"tournament\", pressure=9)\n",
    "        .repair(\"round\")\n",
    "        .external_archive(size=56, archive_type=\"hypervolume\")\n",
    "        \n",
    "        .build()\n",
    "    )\n",
    "\n",
    "\n",
    "# Check available backends\n",
    "print(\"Registered backends:\", list(KERNELS.keys()))\n",
    "\n",
    "# Test which ones are actually available\n",
    "available = []\n",
    "for name in KERNELS:\n",
    "    try:\n",
    "        resolve_kernel(name)\n",
    "        available.append(name)\n",
    "        print(f\"  ✓ {name}: available\")\n",
    "    except ImportError as e:\n",
    "        print(f\"  ✗ {name}: {e}\")\n",
    "\n",
    "print(f\"\\nUsable backends: {available}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bada0b1",
   "metadata": {},
   "source": [
    "## 1. Backend Selection\n",
    "\n",
    "Select a backend via `optimize(..., engine=...)`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22cc403c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NumPy backend (always available)\n",
    "numpy_config = make_autonsgaii_config()\n",
    "\n",
    "# Numba backend (if installed)\n",
    "try:\n",
    "    numba_config = make_autonsgaii_config()\n",
    "    has_numba = True\n",
    "    print(\"Numba backend: available\")\n",
    "except Exception:\n",
    "    has_numba = False\n",
    "    print(\"Numba backend: not installed\")\n",
    "\n",
    "# MooCore backend (if installed)\n",
    "try:\n",
    "    moocore_config = make_autonsgaii_config()\n",
    "    has_moocore = True\n",
    "    print(\"MooCore backend: available\")\n",
    "except Exception:\n",
    "    has_moocore = False\n",
    "    print(\"MooCore backend: not installed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "648d5229",
   "metadata": {},
   "source": [
    "## 2. Performance Benchmark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81a75a8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def benchmark_backend(engine_name, problem, max_evals=5000, seed=42):\n",
    "    \"\"\"Run optimization and measure time.\"\"\"\n",
    "    config = make_autonsgaii_config()\n",
    "\n",
    "    start = time.time()\n",
    "    result = optimize(\n",
    "        problem=problem,\n",
    "        algorithm=\"nsgaii\",\n",
    "        algorithm_config=config,\n",
    "        termination=(\"n_eval\", max_evals),\n",
    "        seed=seed,\n",
    "        engine=engine_name,\n",
    "    )\n",
    "    elapsed = time.time() - start\n",
    "\n",
    "    return {\n",
    "        \"engine\": engine_name,\n",
    "        \"time\": elapsed,\n",
    "        \"solutions\": len(result.F),\n",
    "        \"result\": result,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44adce54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Benchmark available backends\n",
    "zdt1 = ZDT1(n_var=30)\n",
    "MAX_EVALS = 10000\n",
    "\n",
    "benchmarks = {}\n",
    "\n",
    "print(f\"Benchmarking on ZDT1 ({MAX_EVALS} evaluations)...\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "# NumPy (always available)\n",
    "benchmarks[\"numpy\"] = benchmark_backend(\"numpy\", zdt1, MAX_EVALS)\n",
    "print(f\"NumPy:   {benchmarks['numpy']['time']:.3f}s\")\n",
    "\n",
    "# Numba (if available)\n",
    "if has_numba:\n",
    "    # Warm-up run for JIT compilation\n",
    "    _ = benchmark_backend(\"numba\", zdt1, 500)\n",
    "    benchmarks[\"numba\"] = benchmark_backend(\"numba\", zdt1, MAX_EVALS)\n",
    "    print(f\"Numba:   {benchmarks['numba']['time']:.3f}s\")\n",
    "\n",
    "# MooCore (if available)\n",
    "if has_moocore:\n",
    "    benchmarks[\"moocore\"] = benchmark_backend(\"moocore\", zdt1, MAX_EVALS)\n",
    "    print(f\"MooCore: {benchmarks['moocore']['time']:.3f}s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03b44347",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize benchmark results\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12, 4))\n",
    "\n",
    "# Runtime comparison\n",
    "engines = list(benchmarks.keys())\n",
    "times = [benchmarks[e][\"time\"] for e in engines]\n",
    "colors = plt.cm.viridis(np.linspace(0.2, 0.8, len(engines)))\n",
    "\n",
    "axes[0].bar(engines, times, color=colors)\n",
    "axes[0].set_ylabel(\"Runtime (seconds)\")\n",
    "axes[0].set_title(f\"Backend Runtime ({MAX_EVALS} evals)\")\n",
    "for i, (e, t) in enumerate(zip(engines, times)):\n",
    "    axes[0].text(i, t + 0.05, f\"{t:.2f}s\", ha=\"center\", fontsize=10)\n",
    "\n",
    "# Speedup relative to NumPy\n",
    "numpy_time = benchmarks[\"numpy\"][\"time\"]\n",
    "speedups = [numpy_time / benchmarks[e][\"time\"] for e in engines]\n",
    "\n",
    "axes[1].bar(engines, speedups, color=colors)\n",
    "axes[1].axhline(1.0, color=\"red\", linestyle=\"--\", alpha=0.5, label=\"NumPy baseline\")\n",
    "axes[1].set_ylabel(\"Speedup (vs NumPy)\")\n",
    "axes[1].set_title(\"Relative Performance\")\n",
    "for i, (e, s) in enumerate(zip(engines, speedups)):\n",
    "    axes[1].text(i, s + 0.05, f\"{s:.2f}x\", ha=\"center\", fontsize=10)\n",
    "axes[1].legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "681ea10a",
   "metadata": {},
   "source": [
    "## 3. Scaling with Population Size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f86a30af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test scaling with population size\n",
    "pop_sizes = [56]\n",
    "scaling_results = {e: [] for e in available}\n",
    "\n",
    "print(\"Testing population scaling...\")\n",
    "for pop_size in pop_sizes:\n",
    "    print(f\"  Pop size {pop_size}: \", end=\"\")\n",
    "    for engine in available:\n",
    "        config = make_autonsgaii_config()\n",
    "        start = time.time()\n",
    "        _ = optimize(\n",
    "            problem=zdt1,\n",
    "            algorithm=\"nsgaii\",\n",
    "            algorithm_config=config,\n",
    "            termination=(\"n_eval\", 5000),\n",
    "            seed=42,\n",
    "            engine=engine,\n",
    "        )\n",
    "        elapsed = time.time() - start\n",
    "        scaling_results[engine].append(elapsed)\n",
    "        print(f\"{engine}={elapsed:.2f}s \", end=\"\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e3f7f6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot scaling results\n",
    "fig, ax = plt.subplots(figsize=(8, 5))\n",
    "\n",
    "markers = [\"o\", \"s\", \"^\"]\n",
    "for i, engine in enumerate(available):\n",
    "    ax.plot(pop_sizes, scaling_results[engine], marker=markers[i % len(markers)], linewidth=2, markersize=8, label=engine.upper())\n",
    "\n",
    "ax.set_xlabel(\"Population Size\")\n",
    "ax.set_ylabel(\"Runtime (seconds)\")\n",
    "ax.set_title(\"Backend Scaling with Population Size\")\n",
    "ax.legend()\n",
    "ax.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca6ee84e",
   "metadata": {},
   "source": [
    "## 4. Backend-Specific Features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "numpy-feature",
   "metadata": {},
   "source": [
    "### NumPy Backend\n",
    "- Pure NumPy vectorized operations\n",
    "- No additional dependencies\n",
    "- Good baseline performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd500bcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NumPy kernel details\n",
    "from vamos.foundation.kernel.numpy_backend import NumPyKernel\n",
    "\n",
    "numpy_kernel = NumPyKernel()\n",
    "print(\"NumPy Kernel Operations:\")\n",
    "print(f\"  - fast_non_dominated_sort()\")\n",
    "print(f\"  - compute_crowding()\")\n",
    "print(f\"  - survival_selection()\")\n",
    "print(f\"  - create_offspring()\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6a3f87f",
   "metadata": {},
   "source": [
    "### Numba Backend\n",
    "- JIT-compiled hot paths\n",
    "- First run has compilation overhead\n",
    "- Significant speedup on large populations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d676715",
   "metadata": {},
   "outputs": [],
   "source": [
    "if has_numba:\n",
    "    print(\"Numba Backend Features:\")\n",
    "    print(\"  - JIT-compiled non-dominated sorting\")\n",
    "    print(\"  - JIT-compiled crowding distance\")\n",
    "    print(\"  - Cached compilation (faster on subsequent runs)\")\n",
    "    print(\"\\n  Note: First run includes JIT compilation overhead.\")\n",
    "    print(\"        Subsequent runs are significantly faster.\")\n",
    "else:\n",
    "    print(\"Numba not installed. Install with:\")\n",
    "    print(\"  pip install numba>=0.57\")\n",
    "    print(\"  # or\")\n",
    "    print('  pip install -e \".[backends]\"')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "numba-warmup",
   "metadata": {},
   "outputs": [],
   "source": [
    "if has_numba:\n",
    "    print(\"Numba JIT Warm-up Analysis:\")\n",
    "    print(\"---------------------------\")\n",
    "\n",
    "    # Use a fresh problem type (DTLZ2) to potentially trigger new JIT paths\n",
    "    warmup_prob = DTLZ2(n_var=10, n_obj=3)\n",
    "    warmup_config = make_autonsgaii_config()\n",
    "\n",
    "    # Run 1: Cold Start (Compilation + Execution)\n",
    "    start1 = time.time()\n",
    "    _ = optimize(\n",
    "        problem=warmup_prob, algorithm=\"nsgaii\", algorithm_config=warmup_config, termination=(\"n_eval\", 1000), seed=1\n",
    "    )\n",
    "    cold_time = time.time() - start1\n",
    "\n",
    "    # Run 2: Warm Start (Execution only)\n",
    "    start2 = time.time()\n",
    "    _ = optimize(\n",
    "        problem=warmup_prob, algorithm=\"nsgaii\", algorithm_config=warmup_config, termination=(\"n_eval\", 1000), seed=2\n",
    "    )\n",
    "    warm_time = time.time() - start2\n",
    "\n",
    "    print(f\"Cold Run (Compilation): {cold_time:.4f}s\")\n",
    "    print(f\"Warm Run (Execution):   {warm_time:.4f}s\")\n",
    "    print(f\"JIT Overhead:           {cold_time - warm_time:.4f}s\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bf0ebc6",
   "metadata": {},
   "source": [
    "### MooCore Backend\n",
    "- C++ implementation of performance indicators\n",
    "- Particularly fast for hypervolume calculations\n",
    "- Required for SMS-EMOA efficiency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ddad363",
   "metadata": {},
   "outputs": [],
   "source": [
    "if has_moocore:\n",
    "    from vamos.foundation.metrics import moocore_indicators as mi\n",
    "\n",
    "    print(\"MooCore Backend Features:\")\n",
    "    print(\"  - Fast hypervolume calculation\")\n",
    "    print(\"  - Epsilon indicator\")\n",
    "    print(\"  - IGD/IGD+ indicators\")\n",
    "\n",
    "    # Benchmark hypervolume\n",
    "    F_test = np.random.rand(100, 2)\n",
    "    ref = np.array([1.1, 1.1])\n",
    "\n",
    "    start = time.time()\n",
    "    for _ in range(100):\n",
    "        hv = mi.hv_wrapper(F_test, ref)\n",
    "    moocore_time = time.time() - start\n",
    "\n",
    "    print(f\"\\n  MooCore HV: {moocore_time:.4f}s for 100 calculations\")\n",
    "else:\n",
    "    print(\"MooCore not installed. Install with:\")\n",
    "    print(\"  pip install moocore>=0.4\")\n",
    "    print(\"  # or\")\n",
    "    print('  pip install -e \".[backends]\"')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "065ad0e6",
   "metadata": {},
   "source": [
    "## 5. Solution Quality Verification\n",
    "\n",
    "Verify that all backends produce equivalent results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "785b0c96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare solution quality across backends\n",
    "from vamos.foundation.metrics.hypervolume import hypervolume\n",
    "\n",
    "ref_point = np.array([1.1, 1.1])\n",
    "\n",
    "print(\"Solution Quality Comparison:\")\n",
    "print(\"-\" * 50)\n",
    "print(f\"{'Backend':<12} {'Solutions':>10} {'HV':>12}\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "for engine, data in benchmarks.items():\n",
    "    hv = hypervolume(data[\"result\"].F, ref_point)\n",
    "    print(f\"{engine:<12} {data['solutions']:>10} {hv:>12.6f}\")\n",
    "\n",
    "print(\"\\nNote: Small HV differences are due to stochastic nature.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea333070",
   "metadata": {},
   "outputs": [],
   "source": [
    "from vamos.foundation.metrics.pareto import pareto_filter\n",
    "\n",
    "# Overlay Pareto fronts from different backends\n",
    "fig, ax = plt.subplots(figsize=(9, 6))\n",
    "\n",
    "fronts = []\n",
    "for data in benchmarks.values():\n",
    "    F = data[\"result\"].front()\n",
    "    if F is not None and F.size:\n",
    "        fronts.append(F)\n",
    "\n",
    "if fronts:\n",
    "    F_all = np.vstack(fronts)\n",
    "    F_plot = pareto_filter(F_all)\n",
    "    if F_plot is not None and F_plot.size:\n",
    "        ax.scatter(F_plot[:, 0], F_plot[:, 1], s=30, alpha=0.7, c=\"steelblue\", label=\"Union front\")\n",
    "\n",
    "# True Pareto front\n",
    "f1_true = np.linspace(0, 1, 100)\n",
    "f2_true = 1 - np.sqrt(f1_true)\n",
    "ax.plot(f1_true, f2_true, \"k--\", linewidth=2, alpha=0.5, label=\"True PF\")\n",
    "\n",
    "ax.set_xlabel(\"f1\")\n",
    "ax.set_ylabel(\"f2\")\n",
    "ax.set_title(\"Backend Comparison: Pareto Fronts\")\n",
    "ax.legend(loc=\"upper right\")\n",
    "ax.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7d04926",
   "metadata": {},
   "source": [
    "## 6. Recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "323bc56c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\"\"\n",
    "╔══════════════════════════════════════════════════════════════════════╗\n",
    "║                    BACKEND SELECTION GUIDE                           ║\n",
    "╠══════════════════════════════════════════════════════════════════════╣\n",
    "║ SCENARIO                      │ RECOMMENDED BACKEND                  ║\n",
    "╠═══════════════════════════════╪══════════════════════════════════════╣\n",
    "║ Quick experiments, portability│ NumPy (default, no dependencies)     ║\n",
    "║ Large populations (>200)      │ Numba (JIT speedup)                  ║\n",
    "║ Many evaluations (>50k)       │ Numba (accumulated speedup)          ║\n",
    "║ SMS-EMOA algorithm            │ MooCore (fast HV calculation)        ║\n",
    "║ Production/benchmarking       │ Numba or MooCore                     ║\n",
    "╠═══════════════════════════════╧══════════════════════════════════════╣\n",
    "║ INSTALL BACKENDS:                                                    ║\n",
    "║   pip install -e \".[backends]\"  # Installs numba + moocore           ║\n",
    "╚══════════════════════════════════════════════════════════════════════╝\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ba13f86",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "**Backend Selection:**\n",
    "```python\n",
    "# NumPy (default, always available)\n",
    "config = make_autonsgaii_config()\n",
    "\n",
    "# Numba (faster, requires numba package)\n",
    "config = make_autonsgaii_config()\n",
    "\n",
    "# MooCore (fastest for HV, requires moocore package)\n",
    "config = make_autonsgaii_config()\n",
    "```\n",
    "\n",
    "**Installation:**\n",
    "```bash\n",
    "# Core only (NumPy backend)\n",
    "pip install -e .\n",
    "\n",
    "# With accelerated backends\n",
    "pip install -e \".[backends]\"\n",
    "```\n",
    "\n",
    "**Performance Tips:**\n",
    "1. Use NumPy for quick experiments and prototyping\n",
    "2. Switch to Numba for production runs with large populations\n",
    "3. Use MooCore for hypervolume-intensive algorithms (SMS-EMOA)\n",
    "4. First Numba run includes JIT compilation overhead\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}