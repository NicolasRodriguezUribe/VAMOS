{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "intro",
   "metadata": {},
   "source": [
    "# Paper Benchmarking: Cross-Framework Rigor and Performance\n",
    "\n",
    "This notebook provides a paper-ready benchmarking template:\n",
    "- Compare VAMOS with pymoo, jMetalPy, Platypus, and DEAP on ZDT/DTLZ/WFG with identical budgets.\n",
    "- Report HV and IGD, plus Friedman test and post-hoc pairwise Wilcoxon.\n",
    "- Benchmark vectorized vs baseline evaluation and VAMOS backends (NumPy/Numba/MooCore).\n",
    "- Record hardware details for reproducibility.\n",
    "\n",
    "Notes:\n",
    "- Defaults are small for interactive runs; increase budgets and seeds for a paper.\n",
    "- Missing optional dependencies are skipped automatically.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "deps",
   "metadata": {},
   "source": [
    "## Optional dependencies\n",
    "\n",
    "Recommended extras:\n",
    "- pip install -e \".[backends,benchmarks,notebooks]\"\n",
    "- pip install pymoo jmetalpy platypus-opt deap\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "imports",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import time\n",
    "import random\n",
    "import platform\n",
    "import json\n",
    "import io\n",
    "from contextlib import redirect_stdout\n",
    "import importlib.metadata as im\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from vamos import optimize, OptimizeConfig, NSGAIIConfig, ZDT1, DTLZ2, WFG4\n",
    "from vamos.foundation.metrics.hv_zdt import get_zdt_reference_front\n",
    "from vamos.foundation.metrics.hypervolume import compute_hypervolume\n",
    "from vamos.ux.analysis.stats import friedman_test, pairwise_wilcoxon, plot_critical_distance\n",
    "from vamos.foundation.kernel.registry import KERNELS, resolve_kernel\n",
    "\n",
    "plt.style.use(\"ggplot\")\n",
    "\n",
    "# Paper-ready styling\n",
    "plt.rcParams.update({\n",
    "    \"font.family\": \"serif\",\n",
    "    \"font.serif\": [\"Times New Roman\", \"DejaVu Serif\"],\n",
    "    \"font.size\": 10,\n",
    "    \"axes.labelsize\": 10,\n",
    "    \"axes.titlesize\": 11,\n",
    "    \"xtick.labelsize\": 9,\n",
    "    \"ytick.labelsize\": 9,\n",
    "    \"legend.fontsize\": 9,\n",
    "    \"figure.figsize\": (6, 4),\n",
    "    \"figure.dpi\": 300,\n",
    "    \"savefig.dpi\": 300,\n",
    "    \"savefig.bbox\": \"tight\",\n",
    "})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "hardware",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>platform</th>\n",
       "      <th>processor</th>\n",
       "      <th>cpu_count</th>\n",
       "      <th>python</th>\n",
       "      <th>memory_gb</th>\n",
       "      <th>rss_mb</th>\n",
       "      <th>git_commit</th>\n",
       "      <th>git_dirty</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Windows-11-10.0.26200-SP0</td>\n",
       "      <td>Intel64 Family 6 Model 170 Stepping 4, Genuine...</td>\n",
       "      <td>22</td>\n",
       "      <td>3.12.3</td>\n",
       "      <td>33.88</td>\n",
       "      <td>183.48</td>\n",
       "      <td>4bebf59</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    platform  \\\n",
       "0  Windows-11-10.0.26200-SP0   \n",
       "\n",
       "                                           processor  cpu_count  python  \\\n",
       "0  Intel64 Family 6 Model 170 Stepping 4, Genuine...         22  3.12.3   \n",
       "\n",
       "   memory_gb  rss_mb git_commit  git_dirty  \n",
       "0      33.88  183.48    4bebf59       True  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "try:\n",
    "    import psutil\n",
    "    HAS_PSUTIL = True\n",
    "except Exception:\n",
    "    psutil = None\n",
    "    HAS_PSUTIL = False\n",
    "\n",
    "def get_hardware_info():\n",
    "    info = {\n",
    "        \"platform\": platform.platform(),\n",
    "        \"processor\": platform.processor(),\n",
    "        \"cpu_count\": os.cpu_count(),\n",
    "        \"python\": sys.version.split()[0],\n",
    "    }\n",
    "    if HAS_PSUTIL:\n",
    "        info[\"memory_gb\"] = round(psutil.virtual_memory().total / 1e9, 2)\n",
    "        info[\"rss_mb\"] = round(psutil.Process(os.getpid()).memory_info().rss / (1024 ** 2), 2)\n",
    "    else:\n",
    "        info[\"memory_gb\"] = None\n",
    "        info[\"rss_mb\"] = None\n",
    "    return info\n",
    "\n",
    "hardware = get_hardware_info()\n",
    "\n",
    "# Git metadata\n",
    "try:\n",
    "    import subprocess\n",
    "    git_commit = subprocess.check_output([\"git\", \"rev-parse\", \"--short\", \"HEAD\"]).decode(\"ascii\").strip()\n",
    "    git_status = subprocess.check_output([\"git\", \"status\", \"--porcelain\"]).decode(\"ascii\").strip()\n",
    "    is_dirty = bool(git_status)\n",
    "    hardware[\"git_commit\"] = git_commit\n",
    "    hardware[\"git_dirty\"] = is_dirty\n",
    "except Exception:\n",
    "    hardware[\"git_commit\"] = \"unknown\"\n",
    "    hardware[\"git_dirty\"] = \"unknown\"\n",
    "pd.DataFrame([hardware])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "repro_md",
   "metadata": {},
   "source": [
    "## Reproducibility metadata\n",
    "\n",
    "Capture package versions and math library config for the paper appendix.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "repro_meta",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Build Dependencies:\n",
      "  blas:\n",
      "    detection method: pkgconfig\n",
      "    found: true\n",
      "    include directory: C:/Users/runneradmin/AppData/Local/Temp/cibw-run-q7k2ejt3/cp312-win_amd64/build/venv/Lib/site-packages/scipy_openblas64/include\n",
      "    lib directory: C:/Users/runneradmin/AppData/Local/Temp/cibw-run-q7k2ejt3/cp312-win_amd64/build/venv/Lib/site-packages/scipy_openblas64/lib\n",
      "    name: scipy-openblas\n",
      "    openblas configuration: OpenBLAS 0.3.30  USE64BITINT DYNAMIC_ARCH NO_AFFINITY\n",
      "      Haswell MAX_THREADS=24\n",
      "    pc file directory: D:/a/numpy-release/numpy-release/.openblas\n",
      "    version: 0.3.30\n",
      "  lapack:\n",
      "    detection method: pkgconfig\n",
      "    found: true\n",
      "    include directory: C:/Users/runneradmin/AppData/Local/Temp/cibw-run-q7k2ejt3/cp312-win_amd64/build/venv/Lib/site-packages/scipy_openblas64/include\n",
      "    lib directory: C:/Users/runneradmin/AppData/Local/Temp/cibw-run-q7k2ejt3/cp312-win_amd64/build/venv/Lib/site-packages/scipy_openblas64/lib\n",
      "    name: scipy-openblas\n",
      "    openblas configuration: OpenBLAS 0.3.30  USE64BITINT DYNAMIC_ARCH NO_AFFINITY\n",
      "      Haswell MAX_THREADS=24\n",
      "    pc file directory: D:/a/numpy-release/numpy-release/.openblas\n",
      "    version: 0.3.30\n",
      "Compilers:\n",
      "  c:\n",
      "    commands: cl\n",
      "    linker: link\n",
      "    name: msvc\n",
      "    version: 19.44.35219\n",
      "  c++:\n",
      "    commands: cl\n",
      "    linker: link\n",
      "    name: msvc\n",
      "    version: 19.44.35219\n",
      "  cython:\n",
      "    commands: cython\n",
      "    linker: cython\n",
      "    name: cython\n",
      "    version: 3.2.1\n",
      "Machine Information:\n",
      "  build:\n",
      "    cpu: x86_64\n",
      "    endian: little\n",
      "    family: x86_64\n",
      "    system: windows\n",
      "  host:\n",
      "    cpu: x86_64\n",
      "    endian: little\n",
      "    family: x86_64\n",
      "    system: windows\n",
      "Python Information:\n",
      "  path: C:\\Users\\runneradmin\\AppData\\Local\\Temp\\build-env-fls87aak\\Scripts\\python.exe\n",
      "  version: '3.12'\n",
      "SIMD Extensions:\n",
      "  baseline:\n",
      "  - SSE\n",
      "  - SSE2\n",
      "  - SSE3\n",
      "  found:\n",
      "  - SSSE3\n",
      "  - SSE41\n",
      "  - POPCNT\n",
      "  - SSE42\n",
      "  - AVX\n",
      "  - F16C\n",
      "  - FMA3\n",
      "  - AVX2\n",
      "  not found:\n",
      "  - AVX512F\n",
      "  - AVX512CD\n",
      "  - AVX512_SKX\n",
      "  - AVX512_CLX\n",
      "  - AVX512_CNL\n",
      "  - AVX512_ICL\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def package_version(name):\n",
    "    try:\n",
    "        return im.version(name)\n",
    "    except Exception:\n",
    "        return None\n",
    "\n",
    "packages = [\n",
    "    \"vamos\",\n",
    "    \"numpy\",\n",
    "    \"scipy\",\n",
    "    \"numba\",\n",
    "    \"moocore\",\n",
    "    \"pymoo\",\n",
    "    \"jmetalpy\",\n",
    "    \"platypus-opt\",\n",
    "    \"deap\",\n",
    "    \"pandas\",\n",
    "    \"matplotlib\",\n",
    "]\n",
    "versions = {pkg: package_version(pkg) for pkg in packages}\n",
    "\n",
    "env_vars = {\n",
    "    \"OMP_NUM_THREADS\": os.environ.get(\"OMP_NUM_THREADS\"),\n",
    "    \"MKL_NUM_THREADS\": os.environ.get(\"MKL_NUM_THREADS\"),\n",
    "    \"OPENBLAS_NUM_THREADS\": os.environ.get(\"OPENBLAS_NUM_THREADS\"),\n",
    "    \"NUMEXPR_NUM_THREADS\": os.environ.get(\"NUMEXPR_NUM_THREADS\"),\n",
    "    \"NUMBA_NUM_THREADS\": os.environ.get(\"NUMBA_NUM_THREADS\"),\n",
    "}\n",
    "\n",
    "buf = io.StringIO()\n",
    "with redirect_stdout(buf):\n",
    "    np.__config__.show()\n",
    "np_config = buf.getvalue()\n",
    "\n",
    "versions_df = pd.DataFrame.from_dict(versions, orient=\"index\", columns=[\"version\"])\n",
    "env_df = pd.DataFrame([env_vars])\n",
    "\n",
    "versions_df\n",
    "env_df\n",
    "print(np_config)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "config_md",
   "metadata": {},
   "source": [
    "## Benchmark configuration\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "config",
   "metadata": {},
   "outputs": [],
   "source": [
    "POP_SIZE = 100\n",
    "MAX_EVALS = 10000\n",
    "SEEDS = [1, 2, 3, 4, 5]\n",
    "\n",
    "COMPARISON_MODE = \"matched\"  # \"native_defaults\" where supported\n",
    "\n",
    "RUN_QOT = True\n",
    "QOT_BUDGETS = [0.25, 0.5, 1.0]\n",
    "QOT_SEEDS = [1]\n",
    "\n",
    "RUN_SCALING = True\n",
    "SCALING_FRAMEWORKS = [\"vamos\"]\n",
    "SCALING_POP_SIZES = [50, 100, 200]\n",
    "SCALING_N_VARS = [30, 60, 100]\n",
    "SCALING_N_OBJS = [2, 3, 5]\n",
    "SCALING_MAX_EVALS = 4000\n",
    "SCALING_SEED = 1\n",
    "\n",
    "PROBLEMS = [\n",
    "    {\"key\": \"zdt1\", \"label\": \"ZDT1\", \"n_var\": 30, \"n_obj\": 2},\n",
    "    {\"key\": \"dtlz2\", \"label\": \"DTLZ2\", \"n_var\": 12, \"n_obj\": 2},\n",
    "    {\"key\": \"wfg4\", \"label\": \"WFG4\", \"n_var\": 24, \"n_obj\": 2},\n",
    "]\n",
    "\n",
    "FRAMEWORKS = [\"vamos\", \"pymoo\", \"jmetalpy\", \"platypus\", \"deap\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "availability",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pymoo</th>\n",
       "      <th>jmetalpy</th>\n",
       "      <th>platypus</th>\n",
       "      <th>deap</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   pymoo  jmetalpy  platypus  deap\n",
       "0   True      True      True  True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def module_available(name):\n",
    "    try:\n",
    "        __import__(name)\n",
    "        return True\n",
    "    except Exception:\n",
    "        return False\n",
    "\n",
    "HAS_PYMOO = module_available(\"pymoo\")\n",
    "HAS_JMETAL = module_available(\"jmetal\")\n",
    "HAS_PLATYPUS = module_available(\"platypus\")\n",
    "HAS_DEAP = module_available(\"deap\")\n",
    "\n",
    "availability = {\n",
    "    \"pymoo\": HAS_PYMOO,\n",
    "    \"jmetalpy\": HAS_JMETAL,\n",
    "    \"platypus\": HAS_PLATYPUS,\n",
    "    \"deap\": HAS_DEAP,\n",
    "}\n",
    "pd.DataFrame([availability])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ref_md",
   "metadata": {},
   "source": [
    "## Reference fronts and metrics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "make_problem",
   "metadata": {},
   "outputs": [],
   "source": [
    "def wfg_params(spec):\n",
    "    n_var = spec[\"n_var\"]\n",
    "    n_obj = spec[\"n_obj\"]\n",
    "    k = max(4, 2 * (n_obj - 1))\n",
    "    l = n_var - k\n",
    "    if l < 1:\n",
    "        raise ValueError(\n",
    "            f\"WFG requires n_var >= k+1 (got n_var={n_var}, k={k}).\"\n",
    "        )\n",
    "    return k, l\n",
    "\n",
    "def make_vamos_problem(spec):\n",
    "    if spec[\"key\"] == \"zdt1\":\n",
    "        return ZDT1(n_var=spec[\"n_var\"])\n",
    "    if spec[\"key\"] == \"dtlz2\":\n",
    "        return DTLZ2(n_var=spec[\"n_var\"], n_obj=spec[\"n_obj\"])\n",
    "    if spec[\"key\"] == \"wfg4\":\n",
    "        try:\n",
    "            k, l = wfg_params(spec)\n",
    "            return WFG4(n_var=spec[\"n_var\"], n_obj=spec[\"n_obj\"], k=k, l=l)\n",
    "        except ImportError as exc:\n",
    "            print(f\"WFG requires pymoo: {exc}\")\n",
    "            return None\n",
    "        except ValueError as exc:\n",
    "            print(f\"Invalid WFG parameters: {exc}\")\n",
    "            return None\n",
    "    raise ValueError(f\"Unknown problem {spec['key']}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ref_front",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pareto_front_2d(F):\n",
    "    if F.size == 0:\n",
    "        return F\n",
    "    idx = np.argsort(F[:, 0])\n",
    "    F_sorted = F[idx]\n",
    "    front = []\n",
    "    best_f2 = np.inf\n",
    "    for f1, f2 in F_sorted:\n",
    "        if f2 < best_f2:\n",
    "            front.append([f1, f2])\n",
    "            best_f2 = f2\n",
    "    return np.asarray(front, dtype=float)\n",
    "\n",
    "def sample_reference_front(spec, n_samples=5000, seed=123):\n",
    "    problem = make_vamos_problem(spec)\n",
    "    if problem is None:\n",
    "        return None\n",
    "    rng = np.random.default_rng(seed)\n",
    "    X = rng.uniform(problem.xl, problem.xu, size=(n_samples, problem.n_var))\n",
    "    F = np.empty((n_samples, problem.n_obj))\n",
    "    problem.evaluate(X, {\"F\": F})\n",
    "    return pareto_front_2d(F)\n",
    "\n",
    "def reference_front(spec, n_points=1000):\n",
    "    key = spec[\"key\"]\n",
    "    if key.startswith(\"zdt\"):\n",
    "        return get_zdt_reference_front(key, n_points)\n",
    "    if key == \"dtlz2\":\n",
    "        theta = np.linspace(0.0, np.pi / 2.0, n_points)\n",
    "        return np.column_stack([np.cos(theta), np.sin(theta)])\n",
    "    if key.startswith(\"wfg\"):\n",
    "        if HAS_PYMOO:\n",
    "            try:\n",
    "                from pymoo.problems import get_problem\n",
    "                k, l = wfg_params(spec)\n",
    "                prob = get_problem(\n",
    "                    key,\n",
    "                    n_var=spec[\"n_var\"],\n",
    "                    n_obj=spec[\"n_obj\"],\n",
    "                    k=k,\n",
    "                    l=l,\n",
    "                )\n",
    "                pf = prob.pareto_front(n_points)\n",
    "                if pf is not None:\n",
    "                    return np.asarray(pf, dtype=float)\n",
    "            except Exception as exc:\n",
    "                print(f\"pymoo pareto_front failed for {key}: {exc}\")\n",
    "        return sample_reference_front(spec, n_samples=max(5000, n_points))\n",
    "    raise ValueError(f\"No reference front for {key}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "build_refs",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pymoo pareto_front failed for wfg4: a bytes-like object is required, not 'int'\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['zdt1', 'dtlz2', 'wfg4']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "REF_FRONTS = {}\n",
    "for spec in PROBLEMS:\n",
    "    ref = reference_front(spec)\n",
    "    if ref is None or len(ref) == 0:\n",
    "        print(f\"Skipping {spec['label']} (no reference front).\")\n",
    "        continue\n",
    "    REF_FRONTS[spec[\"key\"]] = ref\n",
    "\n",
    "list(REF_FRONTS.keys())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "metrics",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    from vamos.foundation.metrics import moocore_indicators as mi\n",
    "    HAS_MOOCORE = mi.has_moocore()\n",
    "except Exception:\n",
    "    mi = None\n",
    "    HAS_MOOCORE = False\n",
    "\n",
    "def hv_reference_point(F, ref_front):\n",
    "    worst = np.maximum(np.max(F, axis=0), np.max(ref_front, axis=0))\n",
    "    margin = 0.1 * np.maximum(1.0, np.abs(worst))\n",
    "    return worst + margin\n",
    "\n",
    "def igd(F, ref_front):\n",
    "    F = np.asarray(F, dtype=float)\n",
    "    ref = np.asarray(ref_front, dtype=float)\n",
    "    if F.size == 0 or ref.size == 0:\n",
    "        return np.nan\n",
    "    diff = ref[:, None, :] - F[None, :, :]\n",
    "    dist = np.linalg.norm(diff, axis=2)\n",
    "    return float(np.mean(np.min(dist, axis=1)))\n",
    "\n",
    "def igd_plus(F, ref_front):\n",
    "    F = np.asarray(F, dtype=float)\n",
    "    ref = np.asarray(ref_front, dtype=float)\n",
    "    if F.size == 0 or ref.size == 0:\n",
    "        return np.nan\n",
    "    diff = F[None, :, :] - ref[:, None, :]\n",
    "    diff = np.maximum(diff, 0.0)\n",
    "    dist = np.linalg.norm(diff, axis=2)\n",
    "    return float(np.mean(np.min(dist, axis=1)))\n",
    "\n",
    "def epsilon_additive(F, ref_front):\n",
    "    F = np.asarray(F, dtype=float)\n",
    "    ref = np.asarray(ref_front, dtype=float)\n",
    "    if F.size == 0 or ref.size == 0:\n",
    "        return np.nan\n",
    "    diff = F[None, :, :] - ref[:, None, :]\n",
    "    eps = np.max(diff, axis=2)\n",
    "    min_eps = np.min(eps, axis=1)\n",
    "    return float(np.max(min_eps))\n",
    "\n",
    "def compute_metrics(F, ref_front):\n",
    "    metrics = {\n",
    "        \"hv\": np.nan,\n",
    "        \"hv_norm\": np.nan,\n",
    "        \"igd\": np.nan,\n",
    "        \"igd_plus\": np.nan,\n",
    "        \"epsilon_add\": np.nan,\n",
    "    }\n",
    "    if F is None or len(F) == 0:\n",
    "        return metrics\n",
    "    F = np.asarray(F, dtype=float)\n",
    "    ref_front = np.asarray(ref_front, dtype=float)\n",
    "    if ref_front.size == 0:\n",
    "        return metrics\n",
    "\n",
    "    igd_val = igd(F, ref_front)\n",
    "    igd_plus_val = igd_plus(F, ref_front)\n",
    "    eps_add = epsilon_additive(F, ref_front)\n",
    "\n",
    "    if HAS_MOOCORE:\n",
    "        try:\n",
    "            igd_plus_val = float(mi.IGDPlusIndicator(reference_front=ref_front).compute(F).value)\n",
    "        except Exception:\n",
    "            pass\n",
    "        try:\n",
    "            eps_add = float(mi.EpsilonAdditiveIndicator(reference_front=ref_front).compute(F).value)\n",
    "        except Exception:\n",
    "            pass\n",
    "\n",
    "    hv = np.nan\n",
    "    hv_norm = np.nan\n",
    "    if F.shape[1] == 2:\n",
    "        ref_point = hv_reference_point(F, ref_front)\n",
    "        hv = compute_hypervolume(F, ref_point)\n",
    "        hv_ref = compute_hypervolume(ref_front, ref_point) if len(ref_front) else np.nan\n",
    "        hv_norm = hv / hv_ref if hv_ref and hv_ref > 0 else np.nan\n",
    "\n",
    "    metrics.update(\n",
    "        {\n",
    "            \"hv\": hv,\n",
    "            \"hv_norm\": hv_norm,\n",
    "            \"igd\": igd_val,\n",
    "            \"igd_plus\": igd_plus_val,\n",
    "            \"epsilon_add\": eps_add,\n",
    "        }\n",
    "    )\n",
    "    return metrics\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adapters_md",
   "metadata": {},
   "source": [
    "## Framework adapters\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "adapters",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tracemalloc\n",
    "\n",
    "def run_with_profile(fn, *args, **kwargs):\n",
    "    proc = psutil.Process(os.getpid()) if HAS_PSUTIL else None\n",
    "    rss_before = proc.memory_info().rss / (1024 ** 2) if proc else np.nan\n",
    "    cpu_before = time.process_time()\n",
    "    tracemalloc.start()\n",
    "    start = time.perf_counter()\n",
    "    result = fn(*args, **kwargs)\n",
    "    elapsed = time.perf_counter() - start\n",
    "    cpu_time = time.process_time() - cpu_before\n",
    "    current, peak = tracemalloc.get_traced_memory()\n",
    "    tracemalloc.stop()\n",
    "    rss_after = proc.memory_info().rss / (1024 ** 2) if proc else np.nan\n",
    "    rss_delta = rss_after - rss_before if proc else np.nan\n",
    "    return result, elapsed, peak / (1024 ** 2), cpu_time, rss_after, rss_delta\n",
    "\n",
    "def run_vamos(spec, seed, engine=\"numpy\", max_evals=None, pop_size=None):\n",
    "    problem = make_vamos_problem(spec)\n",
    "    if problem is None:\n",
    "        return None\n",
    "    max_evals = max_evals or MAX_EVALS\n",
    "    pop_size = pop_size or POP_SIZE\n",
    "    cfg = NSGAIIConfig.default(pop_size=pop_size, n_var=problem.n_var, engine=engine)\n",
    "    result = optimize(\n",
    "        OptimizeConfig(\n",
    "            problem=problem,\n",
    "            algorithm=\"nsgaii\",\n",
    "            algorithm_config=cfg,\n",
    "            termination=(\"n_eval\", max_evals),\n",
    "            seed=seed,\n",
    "            engine=engine,\n",
    "        )\n",
    "    )\n",
    "    return np.asarray(result.F, dtype=float)\n",
    "\n",
    "def run_pymoo(spec, seed, max_evals=None, pop_size=None):\n",
    "    if not HAS_PYMOO:\n",
    "        return None\n",
    "    from pymoo.algorithms.moo.nsga2 import NSGA2\n",
    "    from pymoo.operators.crossover.sbx import SBX\n",
    "    from pymoo.operators.mutation.pm import PM\n",
    "    from pymoo.operators.sampling.rnd import FloatRandomSampling\n",
    "    from pymoo.optimize import minimize\n",
    "    from pymoo.problems import get_problem\n",
    "\n",
    "    max_evals = max_evals or MAX_EVALS\n",
    "    pop_size = pop_size or POP_SIZE\n",
    "\n",
    "    key = spec[\"key\"]\n",
    "    if key.startswith(\"zdt\"):\n",
    "        problem = get_problem(key, n_var=spec[\"n_var\"])\n",
    "    elif key.startswith(\"dtlz\"):\n",
    "        problem = get_problem(key, n_var=spec[\"n_var\"], n_obj=spec[\"n_obj\"])\n",
    "    elif key.startswith(\"wfg\"):\n",
    "        try:\n",
    "            k, l = wfg_params(spec)\n",
    "        except ValueError as exc:\n",
    "            print(f\"Invalid WFG parameters: {exc}\")\n",
    "            return None\n",
    "        problem = get_problem(key, n_var=spec[\"n_var\"], n_obj=spec[\"n_obj\"], k=k, l=l)\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "    if COMPARISON_MODE == \"native_defaults\":\n",
    "        algorithm = NSGA2(pop_size=pop_size)\n",
    "    else:\n",
    "        algorithm = NSGA2(\n",
    "            pop_size=pop_size,\n",
    "            sampling=FloatRandomSampling(),\n",
    "            crossover=SBX(prob=0.9, eta=20.0),\n",
    "            mutation=PM(prob=1.0 / spec[\"n_var\"], eta=20.0),\n",
    "            eliminate_duplicates=True,\n",
    "        )\n",
    "    res = minimize(problem, algorithm, (\"n_eval\", max_evals), seed=seed, verbose=False)\n",
    "    return np.asarray(res.F, dtype=float)\n",
    "\n",
    "def run_jmetalpy(spec, seed, max_evals=None, pop_size=None):\n",
    "    if not HAS_JMETAL:\n",
    "        return None\n",
    "    try:\n",
    "        from jmetal.algorithm.multiobjective.nsgaii import NSGAII\n",
    "        from jmetal.operator.crossover import SBXCrossover\n",
    "        from jmetal.operator.mutation import PolynomialMutation\n",
    "        from jmetal.util.termination_criterion import StoppingByEvaluations\n",
    "    except Exception:\n",
    "        return None\n",
    "\n",
    "    max_evals = max_evals or MAX_EVALS\n",
    "    pop_size = pop_size or POP_SIZE\n",
    "\n",
    "    # Set seed for reproducibility\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "\n",
    "    key = spec[\"key\"]\n",
    "    if key == \"zdt1\":\n",
    "        from jmetal.problem.multiobjective.zdt import ZDT1\n",
    "        problem = ZDT1(number_of_variables=spec[\"n_var\"])\n",
    "    elif key == \"dtlz2\":\n",
    "        from jmetal.problem.multiobjective.dtlz import DTLZ2\n",
    "        problem = DTLZ2(number_of_variables=spec[\"n_var\"], number_of_objectives=spec[\"n_obj\"])\n",
    "    elif key == \"wfg4\":\n",
    "        try:\n",
    "            from jmetal.problem.multiobjective.wfg import WFG4\n",
    "            try:\n",
    "                k, _ = wfg_params(spec)\n",
    "            except ValueError as exc:\n",
    "                print(f\"Invalid WFG parameters: {exc}\")\n",
    "                return None\n",
    "            try:\n",
    "                problem = WFG4(\n",
    "                    number_of_variables=spec[\"n_var\"],\n",
    "                    number_of_objectives=spec[\"n_obj\"],\n",
    "                    k=k,\n",
    "                )\n",
    "            except TypeError:\n",
    "                problem = WFG4(\n",
    "                    number_of_variables=spec[\"n_var\"],\n",
    "                    number_of_objectives=spec[\"n_obj\"],\n",
    "                )\n",
    "        except Exception:\n",
    "            return None\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "    algorithm = NSGAII(\n",
    "        problem=problem,\n",
    "        population_size=pop_size,\n",
    "        offspring_population_size=pop_size,\n",
    "        mutation=PolynomialMutation(probability=1.0 / spec[\"n_var\"], distribution_index=20.0),\n",
    "        crossover=SBXCrossover(probability=0.9, distribution_index=20.0),\n",
    "        termination_criterion=StoppingByEvaluations(max_evaluations=max_evals),\n",
    "    )\n",
    "    algorithm.run()\n",
    "    get_result_fn = getattr(algorithm, \"result\", None)\n",
    "    solutions = get_result_fn() if callable(get_result_fn) else []\n",
    "    F = np.array([sol.objectives for sol in solutions], dtype=float)\n",
    "    return F\n",
    "\n",
    "def run_platypus(spec, seed, max_evals=None, pop_size=None):\n",
    "    if not HAS_PLATYPUS:\n",
    "        return None\n",
    "    try:\n",
    "        from platypus import NSGAII, Problem, Real\n",
    "    except Exception:\n",
    "        return None\n",
    "\n",
    "    max_evals = max_evals or MAX_EVALS\n",
    "    pop_size = pop_size or POP_SIZE\n",
    "\n",
    "    random.seed(seed)\n",
    "    problem = make_vamos_problem(spec)\n",
    "    if problem is None:\n",
    "        return None\n",
    "\n",
    "    plat_prob = Problem(problem.n_var, problem.n_obj)\n",
    "    plat_prob.types[:] = [Real(problem.xl, problem.xu) for _ in range(problem.n_var)]\n",
    "\n",
    "    def eval_fn(vars):\n",
    "        X = np.asarray(vars, dtype=float)[None, :]\n",
    "        F = np.empty((1, problem.n_obj))\n",
    "        problem.evaluate(X, {\"F\": F})\n",
    "        return F[0].tolist()\n",
    "\n",
    "    plat_prob.function = eval_fn\n",
    "    algorithm = NSGAII(plat_prob, population_size=pop_size)\n",
    "    algorithm.run(max_evals)\n",
    "    F = np.asarray([s.objectives for s in algorithm.result], dtype=float)\n",
    "    return F\n",
    "\n",
    "def run_deap(spec, seed, max_evals=None, pop_size=None):\n",
    "    if not HAS_DEAP:\n",
    "        return None\n",
    "    from deap import base, creator, tools\n",
    "\n",
    "    max_evals = max_evals or MAX_EVALS\n",
    "    pop_size = pop_size or POP_SIZE\n",
    "\n",
    "    problem = make_vamos_problem(spec)\n",
    "    if problem is None:\n",
    "        return None\n",
    "\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "\n",
    "    n_obj = problem.n_obj\n",
    "    if not hasattr(creator, \"FitnessMin\"):\n",
    "        creator.create(\"FitnessMin\", base.Fitness, weights=tuple([-1.0] * n_obj))\n",
    "    if not hasattr(creator, \"Individual\"):\n",
    "        creator.create(\"Individual\", list, fitness=creator.FitnessMin)\n",
    "\n",
    "    toolbox = base.Toolbox()\n",
    "    toolbox.register(\"attr_float\", random.uniform, problem.xl, problem.xu)\n",
    "    toolbox.register(\"individual\", tools.initRepeat, creator.Individual, toolbox.attr_float, n=problem.n_var)\n",
    "    toolbox.register(\"population\", tools.initRepeat, list, toolbox.individual)\n",
    "\n",
    "    def eval_ind(ind):\n",
    "        X = np.asarray(ind, dtype=float)[None, :]\n",
    "        F = np.empty((1, problem.n_obj))\n",
    "        problem.evaluate(X, {\"F\": F})\n",
    "        return tuple(F[0])\n",
    "\n",
    "    toolbox.register(\"evaluate\", eval_ind)\n",
    "    toolbox.register(\"mate\", tools.cxSimulatedBinaryBounded, low=problem.xl, up=problem.xu, eta=20.0)\n",
    "    toolbox.register(\"mutate\", tools.mutPolynomialBounded, low=problem.xl, up=problem.xu, eta=20.0, indpb=1.0 / problem.n_var)\n",
    "    toolbox.register(\"select\", tools.selNSGA2)\n",
    "\n",
    "    pop = toolbox.population(n=pop_size)\n",
    "    invalid = [ind for ind in pop if not ind.fitness.valid]\n",
    "    fitnesses = map(toolbox.evaluate, invalid)\n",
    "    for ind, fit in zip(invalid, fitnesses):\n",
    "        ind.fitness.values = fit\n",
    "\n",
    "    pop = toolbox.select(pop, len(pop))\n",
    "    n_gen = max(1, max_evals // pop_size)\n",
    "    for _ in range(1, n_gen):\n",
    "        offspring = tools.selTournamentDCD(pop, len(pop))\n",
    "        offspring = list(map(toolbox.clone, offspring))\n",
    "\n",
    "        for ind1, ind2 in zip(offspring[::2], offspring[1::2]):\n",
    "            if random.random() <= 0.9:\n",
    "                toolbox.mate(ind1, ind2)\n",
    "                del ind1.fitness.values, ind2.fitness.values\n",
    "\n",
    "        for mutant in offspring:\n",
    "            if random.random() <= 1.0:\n",
    "                toolbox.mutate(mutant)\n",
    "                del mutant.fitness.values\n",
    "\n",
    "        invalid = [ind for ind in offspring if not ind.fitness.valid]\n",
    "        fitnesses = map(toolbox.evaluate, invalid)\n",
    "        for ind, fit in zip(invalid, fitnesses):\n",
    "            ind.fitness.values = fit\n",
    "\n",
    "        pop = toolbox.select(pop + offspring, pop_size)\n",
    "\n",
    "    F = np.asarray([ind.fitness.values for ind in pop], dtype=float)\n",
    "    return F\n",
    "\n",
    "RUNNERS = {\n",
    "    \"vamos\": run_vamos,\n",
    "    \"pymoo\": run_pymoo,\n",
    "    \"jmetalpy\": run_jmetalpy,\n",
    "    \"platypus\": run_platypus,\n",
    "    \"deap\": run_deap,\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "run_md",
   "metadata": {},
   "source": [
    "## Run benchmarks\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "run_bench",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2025-12-24 01:05:45,279] [jmetal.core.algorithm] [DEBUG] Creating initial set of solutions...\n",
      "[2025-12-24 01:05:45,288] [jmetal.core.algorithm] [DEBUG] Evaluating solutions...\n",
      "[2025-12-24 01:05:45,288] [jmetal.core.algorithm] [DEBUG] Initializing progress...\n",
      "[2025-12-24 01:05:45,291] [jmetal.core.algorithm] [DEBUG] Running main loop until termination criteria is met\n",
      "[2025-12-24 01:05:56,091] [jmetal.core.algorithm] [DEBUG] Finished!\n",
      "[2025-12-24 01:05:56,107] [jmetal.core.algorithm] [DEBUG] Creating initial set of solutions...\n",
      "[2025-12-24 01:05:56,112] [jmetal.core.algorithm] [DEBUG] Evaluating solutions...\n",
      "[2025-12-24 01:05:56,112] [jmetal.core.algorithm] [DEBUG] Initializing progress...\n",
      "[2025-12-24 01:05:56,112] [jmetal.core.algorithm] [DEBUG] Running main loop until termination criteria is met\n",
      "[2025-12-24 01:06:06,518] [jmetal.core.algorithm] [DEBUG] Finished!\n",
      "[2025-12-24 01:06:06,528] [jmetal.core.algorithm] [DEBUG] Creating initial set of solutions...\n",
      "[2025-12-24 01:06:06,535] [jmetal.core.algorithm] [DEBUG] Evaluating solutions...\n",
      "[2025-12-24 01:06:06,537] [jmetal.core.algorithm] [DEBUG] Initializing progress...\n",
      "[2025-12-24 01:06:06,538] [jmetal.core.algorithm] [DEBUG] Running main loop until termination criteria is met\n",
      "[2025-12-24 01:06:16,988] [jmetal.core.algorithm] [DEBUG] Finished!\n",
      "[2025-12-24 01:06:16,994] [jmetal.core.algorithm] [DEBUG] Creating initial set of solutions...\n",
      "[2025-12-24 01:06:17,006] [jmetal.core.algorithm] [DEBUG] Evaluating solutions...\n",
      "[2025-12-24 01:06:17,011] [jmetal.core.algorithm] [DEBUG] Initializing progress...\n",
      "[2025-12-24 01:06:17,011] [jmetal.core.algorithm] [DEBUG] Running main loop until termination criteria is met\n",
      "[2025-12-24 01:06:27,937] [jmetal.core.algorithm] [DEBUG] Finished!\n",
      "[2025-12-24 01:06:27,941] [jmetal.core.algorithm] [DEBUG] Creating initial set of solutions...\n",
      "[2025-12-24 01:06:27,951] [jmetal.core.algorithm] [DEBUG] Evaluating solutions...\n",
      "[2025-12-24 01:06:27,956] [jmetal.core.algorithm] [DEBUG] Initializing progress...\n",
      "[2025-12-24 01:06:27,956] [jmetal.core.algorithm] [DEBUG] Running main loop until termination criteria is met\n",
      "[2025-12-24 01:06:38,378] [jmetal.core.algorithm] [DEBUG] Finished!\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[11]\u001b[39m\u001b[32m, line 15\u001b[39m\n\u001b[32m     13\u001b[39m attempts.append({\u001b[33m\"\u001b[39m\u001b[33mframework\u001b[39m\u001b[33m\"\u001b[39m: framework, \u001b[33m\"\u001b[39m\u001b[33mproblem\u001b[39m\u001b[33m\"\u001b[39m: spec[\u001b[33m\"\u001b[39m\u001b[33mlabel\u001b[39m\u001b[33m\"\u001b[39m], \u001b[33m\"\u001b[39m\u001b[33mseed\u001b[39m\u001b[33m\"\u001b[39m: seed})\n\u001b[32m     14\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m15\u001b[39m     F, elapsed, peak, cpu_time, rss_mb, rss_delta = \u001b[43mrun_with_profile\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     16\u001b[39m \u001b[43m        \u001b[49m\u001b[43mrunner\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     17\u001b[39m \u001b[43m        \u001b[49m\u001b[43mspec\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     18\u001b[39m \u001b[43m        \u001b[49m\u001b[43mseed\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     19\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmax_evals\u001b[49m\u001b[43m=\u001b[49m\u001b[43mMAX_EVALS\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     20\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpop_size\u001b[49m\u001b[43m=\u001b[49m\u001b[43mPOP_SIZE\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     21\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     22\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[32m     23\u001b[39m     failures.append(\n\u001b[32m     24\u001b[39m         {\n\u001b[32m     25\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mframework\u001b[39m\u001b[33m\"\u001b[39m: framework,\n\u001b[32m   (...)\u001b[39m\u001b[32m     29\u001b[39m         }\n\u001b[32m     30\u001b[39m     )\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[10]\u001b[39m\u001b[32m, line 9\u001b[39m, in \u001b[36mrun_with_profile\u001b[39m\u001b[34m(fn, *args, **kwargs)\u001b[39m\n\u001b[32m      7\u001b[39m tracemalloc.start()\n\u001b[32m      8\u001b[39m start = time.perf_counter()\n\u001b[32m----> \u001b[39m\u001b[32m9\u001b[39m result = \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     10\u001b[39m elapsed = time.perf_counter() - start\n\u001b[32m     11\u001b[39m cpu_time = time.process_time() - cpu_before\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[10]\u001b[39m\u001b[32m, line 168\u001b[39m, in \u001b[36mrun_platypus\u001b[39m\u001b[34m(spec, seed, max_evals, pop_size)\u001b[39m\n\u001b[32m    166\u001b[39m plat_prob.function = eval_fn\n\u001b[32m    167\u001b[39m algorithm = NSGAII(plat_prob, population_size=pop_size)\n\u001b[32m--> \u001b[39m\u001b[32m168\u001b[39m \u001b[43malgorithm\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmax_evals\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    169\u001b[39m F = np.asarray([s.objectives \u001b[38;5;28;01mfor\u001b[39;00m s \u001b[38;5;129;01min\u001b[39;00m algorithm.result], dtype=\u001b[38;5;28mfloat\u001b[39m)\n\u001b[32m    170\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m F\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\nicor\\Desktop\\VAMOS\\.venv\\Lib\\site-packages\\platypus\\core.py:741\u001b[39m, in \u001b[36mAlgorithm.run\u001b[39m\u001b[34m(self, condition, callback)\u001b[39m\n\u001b[32m    738\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m extension \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m._extensions:\n\u001b[32m    739\u001b[39m     extension.pre_step(\u001b[38;5;28mself\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m741\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    743\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m extension \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m._extensions:\n\u001b[32m    744\u001b[39m     extension.post_step(\u001b[38;5;28mself\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\nicor\\Desktop\\VAMOS\\.venv\\Lib\\site-packages\\platypus\\algorithms.py:306\u001b[39m, in \u001b[36mNSGAII.step\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    304\u001b[39m     \u001b[38;5;28mself\u001b[39m.initialize()\n\u001b[32m    305\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m306\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43miterate\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    308\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.archive \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    309\u001b[39m     \u001b[38;5;28mself\u001b[39m.result = \u001b[38;5;28mself\u001b[39m.archive\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\nicor\\Desktop\\VAMOS\\.venv\\Lib\\site-packages\\platypus\\algorithms.py:332\u001b[39m, in \u001b[36mNSGAII.iterate\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    329\u001b[39m \u001b[38;5;28mself\u001b[39m.evaluate_all(offspring)\n\u001b[32m    331\u001b[39m offspring.extend(\u001b[38;5;28mself\u001b[39m.population)\n\u001b[32m--> \u001b[39m\u001b[32m332\u001b[39m \u001b[43mnondominated_sort\u001b[49m\u001b[43m(\u001b[49m\u001b[43moffspring\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    333\u001b[39m \u001b[38;5;28mself\u001b[39m.population = nondominated_truncate(offspring, \u001b[38;5;28mself\u001b[39m.population_size)\n\u001b[32m    335\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.archive \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\nicor\\Desktop\\VAMOS\\.venv\\Lib\\site-packages\\platypus\\core.py:1440\u001b[39m, in \u001b[36mnondominated_sort\u001b[39m\u001b[34m(solutions)\u001b[39m\n\u001b[32m   1438\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(solutions) > \u001b[32m0\u001b[39m:\n\u001b[32m   1439\u001b[39m     archive = Archive()\n\u001b[32m-> \u001b[39m\u001b[32m1440\u001b[39m     \u001b[43marchive\u001b[49m\u001b[43m \u001b[49m\u001b[43m+\u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43msolutions\u001b[49m\n\u001b[32m   1442\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m solution \u001b[38;5;129;01min\u001b[39;00m archive:\n\u001b[32m   1443\u001b[39m         solution.rank = rank\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\nicor\\Desktop\\VAMOS\\.venv\\Lib\\site-packages\\platypus\\core.py:1122\u001b[39m, in \u001b[36mArchive.__iadd__\u001b[39m\u001b[34m(self, other)\u001b[39m\n\u001b[32m   1120\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(other, \u001b[33m\"\u001b[39m\u001b[33m__iter__\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m   1121\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m o \u001b[38;5;129;01min\u001b[39;00m other:\n\u001b[32m-> \u001b[39m\u001b[32m1122\u001b[39m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43madd\u001b[49m\u001b[43m(\u001b[49m\u001b[43mo\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1123\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1124\u001b[39m     \u001b[38;5;28mself\u001b[39m.add(other)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\nicor\\Desktop\\VAMOS\\.venv\\Lib\\site-packages\\platypus\\core.py:1061\u001b[39m, in \u001b[36mArchive.add\u001b[39m\u001b[34m(self, solution)\u001b[39m\n\u001b[32m   1040\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34madd\u001b[39m(\u001b[38;5;28mself\u001b[39m, solution):\n\u001b[32m   1041\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Try adding a solution to this archive.\u001b[39;00m\n\u001b[32m   1042\u001b[39m \n\u001b[32m   1043\u001b[39m \u001b[33;03m    Three outcomes can occur when adding a solution:\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m   1059\u001b[39m \u001b[33;03m    :code:`False` otherwise.\u001b[39;00m\n\u001b[32m   1060\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1061\u001b[39m     flags = [\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_dominance\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcompare\u001b[49m\u001b[43m(\u001b[49m\u001b[43msolution\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43ms\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m s \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m._contents]\n\u001b[32m   1062\u001b[39m     dominates = [x > \u001b[32m0\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m flags]\n\u001b[32m   1063\u001b[39m     nondominated = [x == \u001b[32m0\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m flags]\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\nicor\\Desktop\\VAMOS\\.venv\\Lib\\site-packages\\platypus\\core.py:811\u001b[39m, in \u001b[36mParetoDominance.compare\u001b[39m\u001b[34m(self, solution1, solution2)\u001b[39m\n\u001b[32m    809\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(problem.nobjs):\n\u001b[32m    810\u001b[39m     o1 = solution1.objectives[i]\n\u001b[32m--> \u001b[39m\u001b[32m811\u001b[39m     o2 = \u001b[43msolution2\u001b[49m\u001b[43m.\u001b[49m\u001b[43mobjectives\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\n\u001b[32m    813\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m problem.directions[i] == Direction.MAXIMIZE:\n\u001b[32m    814\u001b[39m         o1 = -o1\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\nicor\\Desktop\\VAMOS\\.venv\\Lib\\site-packages\\platypus\\core.py:70\u001b[39m, in \u001b[36mFixedLengthArray.__getitem__\u001b[39m\u001b[34m(self, index)\u001b[39m\n\u001b[32m     67\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m     68\u001b[39m         \u001b[38;5;28mself\u001b[39m._data[index] = value\n\u001b[32m---> \u001b[39m\u001b[32m70\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__getitem__\u001b[39m(\u001b[38;5;28mself\u001b[39m, index):\n\u001b[32m     71\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._data[index]\n\u001b[32m     73\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__str__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "results = []\n",
    "attempts = []\n",
    "failures = []\n",
    "for spec in PROBLEMS:\n",
    "    if spec[\"key\"] not in REF_FRONTS:\n",
    "        continue\n",
    "    ref = REF_FRONTS[spec[\"key\"]]\n",
    "    for framework in FRAMEWORKS:\n",
    "        runner = RUNNERS.get(framework)\n",
    "        if runner is None:\n",
    "            continue\n",
    "        for seed in SEEDS:\n",
    "            attempts.append({\"framework\": framework, \"problem\": spec[\"label\"], \"seed\": seed})\n",
    "            try:\n",
    "                F, elapsed, peak, cpu_time, rss_mb, rss_delta = run_with_profile(\n",
    "                    runner,\n",
    "                    spec,\n",
    "                    seed,\n",
    "                    max_evals=MAX_EVALS,\n",
    "                    pop_size=POP_SIZE,\n",
    "                )\n",
    "            except Exception as exc:\n",
    "                failures.append(\n",
    "                    {\n",
    "                        \"framework\": framework,\n",
    "                        \"problem\": spec[\"label\"],\n",
    "                        \"seed\": seed,\n",
    "                        \"error\": str(exc),\n",
    "                    }\n",
    "                )\n",
    "                print(f\"Skipping {framework} {spec['label']} seed {seed}: {exc}\")\n",
    "                continue\n",
    "            if F is None or len(F) == 0:\n",
    "                continue\n",
    "            metrics = compute_metrics(F, ref)\n",
    "            n_eval = MAX_EVALS\n",
    "            if framework == \"deap\":\n",
    "                n_eval = (MAX_EVALS // POP_SIZE) * POP_SIZE\n",
    "            results.append(\n",
    "                {\n",
    "                    \"framework\": framework,\n",
    "                    \"problem\": spec[\"label\"],\n",
    "                    \"seed\": seed,\n",
    "                    \"n_eval\": n_eval,\n",
    "                    \"max_evals\": MAX_EVALS,\n",
    "                    \"hv\": metrics[\"hv\"],\n",
    "                    \"hv_norm\": metrics[\"hv_norm\"],\n",
    "                    \"igd\": metrics[\"igd\"],\n",
    "                    \"igd_plus\": metrics[\"igd_plus\"],\n",
    "                    \"epsilon_add\": metrics[\"epsilon_add\"],\n",
    "                    \"time_s\": elapsed,\n",
    "                    \"cpu_time_s\": cpu_time,\n",
    "                    \"mem_mb\": peak,\n",
    "                    \"rss_mb\": rss_mb,\n",
    "                    \"rss_mb_delta\": rss_delta,\n",
    "                    \"n_points\": len(F),\n",
    "                    \"pop_size\": POP_SIZE,\n",
    "                    \"n_var\": spec[\"n_var\"],\n",
    "                    \"n_obj\": spec[\"n_obj\"],\n",
    "                    \"comparison_mode\": COMPARISON_MODE,\n",
    "                }\n",
    "            )\n",
    "\n",
    "results_df = pd.DataFrame(results)\n",
    "results_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "summary",
   "metadata": {},
   "outputs": [],
   "source": [
    "if results_df.empty:\n",
    "    print(\"No results collected. Check dependencies and reference fronts.\")\n",
    "else:\n",
    "    summary = (\n",
    "        results_df.groupby([\"problem\", \"framework\"])\n",
    "        .agg(\n",
    "            hv_mean=(\"hv\", \"mean\"),\n",
    "            hv_std=(\"hv\", \"std\"),\n",
    "            hv_norm_mean=(\"hv_norm\", \"mean\"),\n",
    "            hv_norm_std=(\"hv_norm\", \"std\"),\n",
    "            igd_mean=(\"igd\", \"mean\"),\n",
    "            igd_std=(\"igd\", \"std\"),\n",
    "            igd_plus_mean=(\"igd_plus\", \"mean\"),\n",
    "            igd_plus_std=(\"igd_plus\", \"std\"),\n",
    "            eps_add_mean=(\"epsilon_add\", \"mean\"),\n",
    "            eps_add_std=(\"epsilon_add\", \"std\"),\n",
    "            time_mean=(\"time_s\", \"mean\"),\n",
    "            cpu_time_mean=(\"cpu_time_s\", \"mean\"),\n",
    "            mem_mean=(\"mem_mb\", \"mean\"),\n",
    "            rss_mean=(\"rss_mb\", \"mean\"),\n",
    "            n_eval=(\"n_eval\", \"mean\"),\n",
    "        )\n",
    "        .reset_index()\n",
    "    )\n",
    "    summary\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fail_md",
   "metadata": {},
   "source": [
    "## Failure and timeout rates\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fail_summary",
   "metadata": {},
   "outputs": [],
   "source": [
    "failures_df = pd.DataFrame(failures)\n",
    "attempts_df = pd.DataFrame(attempts)\n",
    "\n",
    "if failures_df.empty:\n",
    "    print(\"No failures recorded.\")\n",
    "else:\n",
    "    total = attempts_df.groupby(\"framework\").size().rename(\"attempts\")\n",
    "    failed = failures_df.groupby(\"framework\").size().rename(\"failures\")\n",
    "    failure_rate = (\n",
    "        pd.concat([total, failed], axis=1)\n",
    "        .fillna(0)\n",
    "        .assign(failure_rate=lambda df: df[\"failures\"] / df[\"attempts\"])\n",
    "        .reset_index()\n",
    "    )\n",
    "    failure_rate\n",
    "    failures_df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eff_md",
   "metadata": {},
   "source": [
    "## Efficiency comparison (time and memory)\n",
    "\n",
    "Notes:\n",
    "- mem_mb uses tracemalloc (Python allocations only), so native memory is undercounted.\n",
    "- evals_per_sec normalizes minor budget differences across frameworks.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eff_summary",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not results_df.empty:\n",
    "    results_df = results_df.copy()\n",
    "    results_df[\"evals_per_sec\"] = results_df[\"n_eval\"] / results_df[\"time_s\"]\n",
    "\n",
    "    eff_summary = (\n",
    "        results_df.groupby([\"problem\", \"framework\"])\n",
    "        .agg(\n",
    "            time_mean=(\"time_s\", \"mean\"),\n",
    "            time_std=(\"time_s\", \"std\"),\n",
    "            cpu_time_mean=(\"cpu_time_s\", \"mean\"),\n",
    "            mem_mean=(\"mem_mb\", \"mean\"),\n",
    "            mem_std=(\"mem_mb\", \"std\"),\n",
    "            rss_mean=(\"rss_mb\", \"mean\"),\n",
    "            evals_per_sec_mean=(\"evals_per_sec\", \"mean\"),\n",
    "        )\n",
    "        .reset_index()\n",
    "    )\n",
    "    eff_summary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eff_plot",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not results_df.empty:\n",
    "    metrics = [\n",
    "        (\"time_mean\", \"Runtime (s)\", True),\n",
    "        (\"cpu_time_mean\", \"CPU time (s)\", True),\n",
    "        (\"mem_mean\", \"Peak Python alloc (MB)\", False),\n",
    "        (\"rss_mean\", \"RSS after run (MB)\", False),\n",
    "        (\"evals_per_sec_mean\", \"Eval/s\", True),\n",
    "    ]\n",
    "    for metric, label, logy in metrics:\n",
    "        pivot = eff_summary.pivot(index=\"problem\", columns=\"framework\", values=metric)\n",
    "        ax = pivot.plot(kind=\"bar\", figsize=(10, 4))\n",
    "        ax.set_ylabel(label)\n",
    "        ax.set_title(f\"{label} by framework\")\n",
    "        if logy:\n",
    "            ax.set_yscale(\"log\")\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "stats",
   "metadata": {},
   "outputs": [],
   "source": [
    "CD_STYLE = \"saes\"  # \"saes\" or \"simple\"\n",
    "\n",
    "def holm_correction(p_values):\n",
    "    p_values = np.asarray(p_values, dtype=float)\n",
    "    m = len(p_values)\n",
    "    order = np.argsort(p_values)\n",
    "    adjusted = np.empty(m, dtype=float)\n",
    "    for i, idx in enumerate(order):\n",
    "        adjusted[idx] = min((m - i) * p_values[idx], 1.0)\n",
    "    for i in range(m - 2, -1, -1):\n",
    "        adjusted[order[i]] = max(adjusted[order[i]], adjusted[order[i + 1]])\n",
    "    return adjusted\n",
    "\n",
    "def cliffs_delta(a, b):\n",
    "    a = np.asarray(a, dtype=float)\n",
    "    b = np.asarray(b, dtype=float)\n",
    "    if a.size == 0 or b.size == 0:\n",
    "        return np.nan\n",
    "    diff = a[:, None] - b[None, :]\n",
    "    greater = np.sum(diff > 0)\n",
    "    less = np.sum(diff < 0)\n",
    "    return float((greater - less) / (a.size * b.size))\n",
    "\n",
    "def _saes_ranks(data, maximize):\n",
    "    data = np.asarray(data, dtype=float)\n",
    "    s = 0 if (maximize is False) else 1\n",
    "    if data.ndim != 2:\n",
    "        raise ValueError(\"CD plot data must be 2D.\")\n",
    "    ranks = np.ones(data.shape)\n",
    "    for i in range(data.shape[0]):\n",
    "        values, indices, rep = np.unique(\n",
    "            (-1) ** s * np.sort((-1) ** s * data[i, :]),\n",
    "            return_index=True,\n",
    "            return_counts=True,\n",
    "        )\n",
    "        for j in range(data.shape[1]):\n",
    "            pos = values == data[i, j]\n",
    "            ranks[i, j] += indices[pos].item() + 0.5 * (rep[pos].item() - 1)\n",
    "    return ranks\n",
    "\n",
    "def _nemenyi_cd(alpha, num_alg, num_dataset):\n",
    "    if num_dataset < 2:\n",
    "        return np.nan\n",
    "    try:\n",
    "        from statsmodels.stats.libqsturng import qsturng\n",
    "\n",
    "        q_alpha = qsturng(p=1 - alpha, r=num_alg, v=num_dataset - 1) / np.sqrt(2)\n",
    "    except Exception:\n",
    "        q_alpha = 2.569 if alpha == 0.05 else 2.343\n",
    "    return q_alpha * np.sqrt(num_alg * (num_alg + 1) / (6.0 * num_dataset))\n",
    "\n",
    "def plot_cd_saes_style(data, algo_names, maximize=True, alpha=0.05, width=9):\n",
    "    data = np.asarray(data, dtype=float)\n",
    "    if data.ndim != 2:\n",
    "        raise ValueError(\"CD plot data must be 2D.\")\n",
    "    num_dataset, num_alg = data.shape\n",
    "    cd = _nemenyi_cd(alpha, num_alg, num_dataset)\n",
    "\n",
    "    rranks = _saes_ranks(data, maximize)\n",
    "    avranks = np.mean(rranks, axis=0)\n",
    "    indices = np.argsort(avranks).astype(int)\n",
    "    avranks = avranks[indices]\n",
    "    alg_names = np.asarray(algo_names)[indices]\n",
    "\n",
    "    spoint = int(np.round(num_alg / 2.0))\n",
    "    leftalg = avranks[:spoint]\n",
    "    rightalg = avranks[spoint:]\n",
    "    rows = int(np.ceil(num_alg / 2.0))\n",
    "\n",
    "    highest = int(np.ceil(np.max(avranks)))\n",
    "    lowest = int(np.floor(np.min(avranks)))\n",
    "    span = max(1, highest - lowest)\n",
    "\n",
    "    height = width * (0.8625 * (rows + 1) / 9)\n",
    "    stop, sbottom, sleft, sright = 0.65, 0.1, 0.15, 0.85\n",
    "    lline = sright - sleft\n",
    "\n",
    "    fig = plt.figure(figsize=(width, height), facecolor=\"white\")\n",
    "    ax = fig.add_axes([0, 0, 1, 1])\n",
    "    ax.set_xlim(0, 1)\n",
    "    ax.set_ylim(0, 1)\n",
    "    ax.set_axis_off()\n",
    "\n",
    "    ax.hlines(stop, sleft, sright, color=\"black\", linewidth=3)\n",
    "    for xi in range(highest - lowest + 1):\n",
    "        ax.vlines(\n",
    "            x=sleft + (lline * xi) / span,\n",
    "            ymin=stop,\n",
    "            ymax=stop + 0.05,\n",
    "            color=\"black\",\n",
    "            linewidth=2,\n",
    "        )\n",
    "        ax.text(\n",
    "            x=sleft + (lline * xi) / span,\n",
    "            y=stop + 0.06,\n",
    "            s=str(lowest + xi),\n",
    "            ha=\"center\",\n",
    "            va=\"bottom\",\n",
    "        )\n",
    "        if xi < highest - lowest:\n",
    "            ax.vlines(\n",
    "                x=sleft + (lline * (xi + 0.5)) / span,\n",
    "                ymin=stop,\n",
    "                ymax=stop + 0.025,\n",
    "                color=\"black\",\n",
    "                linewidth=0.7,\n",
    "            )\n",
    "\n",
    "    vspace = 0.5 * (stop - sbottom) / (spoint + 1) if spoint else 0\n",
    "    for i in range(spoint):\n",
    "        x_pos = sleft + (lline * (leftalg[i] - lowest)) / span\n",
    "        y_pos = sbottom + (spoint - 1 - i) * vspace\n",
    "        ax.vlines(x=x_pos, ymin=y_pos, ymax=stop, color=\"red\", linewidth=1)\n",
    "        ax.hlines(y=y_pos, xmin=sleft, xmax=x_pos, color=\"red\", linewidth=1)\n",
    "        ax.text(\n",
    "            x=sleft - 0.01,\n",
    "            y=y_pos,\n",
    "            s=f\"$\\\\mathbf{{{alg_names[i]}}}$\",\n",
    "            ha=\"right\",\n",
    "            va=\"center\",\n",
    "        )\n",
    "\n",
    "    vspace = 0.5 * (stop - sbottom) / (num_alg - spoint + 1) if num_alg - spoint else 0\n",
    "    for i in range(num_alg - spoint):\n",
    "        x_pos = sleft + (lline * (rightalg[i] - lowest)) / span\n",
    "        y_pos = sbottom + i * vspace\n",
    "        ax.vlines(x=x_pos, ymin=y_pos, ymax=stop, color=\"green\", linewidth=1)\n",
    "        ax.hlines(y=y_pos, xmin=x_pos, xmax=sright, color=\"green\", linewidth=1)\n",
    "        ax.text(\n",
    "            x=sright + 0.01,\n",
    "            y=y_pos,\n",
    "            s=f\"$\\\\mathbf{{{alg_names[spoint + i]}}}$\",\n",
    "            ha=\"left\",\n",
    "            va=\"center\",\n",
    "        )\n",
    "\n",
    "    if np.isfinite(cd) and cd > 0:\n",
    "        cd_span = (cd * lline) / span\n",
    "        if sleft + cd_span <= sright:\n",
    "            ax.hlines(y=stop + 0.2, xmin=sleft, xmax=sleft + cd_span, linewidth=1.5)\n",
    "            ax.text(\n",
    "                x=sleft + 0.5 * cd_span,\n",
    "                y=stop + 0.21,\n",
    "                s=f\"CD={cd:.3f}\",\n",
    "                ha=\"center\",\n",
    "                va=\"bottom\",\n",
    "            )\n",
    "        else:\n",
    "            ax.text(\n",
    "                x=(sleft + sright) / 2,\n",
    "                y=stop + 0.2,\n",
    "                s=f\"$\\\\mathbf{{CD={cd:.3f}}}$\",\n",
    "                ha=\"center\",\n",
    "                va=\"bottom\",\n",
    "            )\n",
    "\n",
    "    def _join_alg(avranks, num_alg, cd):\n",
    "        sets = (-1) * np.ones((num_alg, 2))\n",
    "        for i in range(num_alg):\n",
    "            elements = np.where(\n",
    "                np.logical_and(avranks - avranks[i] > 0, avranks - avranks[i] < cd)\n",
    "            )[0]\n",
    "            if elements.size > 0:\n",
    "                sets[i, :] = [avranks[i], avranks[elements[-1]]]\n",
    "        sets = np.delete(sets, np.where(sets[:, 0] < 0)[0], axis=0)\n",
    "        if sets.size == 0:\n",
    "            return sets\n",
    "        group = sets[0, :]\n",
    "        for i in range(1, sets.shape[0]):\n",
    "            if sets[i - 1, 1] < sets[i, 1]:\n",
    "                group = np.vstack((group, sets[i, :]))\n",
    "        return group\n",
    "\n",
    "    if np.isfinite(cd) and cd > 0:\n",
    "        nonsig = _join_alg(avranks, num_alg, cd)\n",
    "        if nonsig.size == 0:\n",
    "            left_lines = np.array([])\n",
    "            right_lines = np.array([])\n",
    "        elif nonsig.ndim == 2:\n",
    "            if nonsig.shape[0] == 2:\n",
    "                left_lines = np.reshape(nonsig[0, :], (1, 2))\n",
    "                right_lines = np.reshape(nonsig[1, :], (1, 2))\n",
    "            else:\n",
    "                left_lines = nonsig[: int(np.round(nonsig.shape[0] / 2.0)), :]\n",
    "                right_lines = nonsig[int(np.round(nonsig.shape[0] / 2.0)) :, :]\n",
    "        else:\n",
    "            left_lines = np.reshape(nonsig, (1, nonsig.shape[0]))\n",
    "\n",
    "        if nonsig.size > 0:\n",
    "            vspace = 0.5 * (stop - sbottom) / (left_lines.shape[0] + 1)\n",
    "            for i in range(left_lines.shape[0]):\n",
    "                ax.hlines(\n",
    "                    y=stop - (i + 1) * vspace,\n",
    "                    xmin=sleft + lline * (left_lines[i, 0] - lowest - 0.025) / span,\n",
    "                    xmax=sleft + lline * (left_lines[i, 1] - lowest + 0.025) / span,\n",
    "                    linewidth=2,\n",
    "                )\n",
    "\n",
    "            if nonsig.ndim == 2 and right_lines.size > 0:\n",
    "                vspace = 0.5 * (stop - sbottom) / (left_lines.shape[0])\n",
    "                for i in range(right_lines.shape[0]):\n",
    "                    ax.hlines(\n",
    "                        y=stop - (i + 1) * vspace,\n",
    "                        xmin=sleft + lline * (right_lines[i, 0] - lowest - 0.025) / span,\n",
    "                        xmax=sleft + lline * (right_lines[i, 1] - lowest + 0.025) / span,\n",
    "                        linewidth=2,\n",
    "                    )\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "def stats_table(df, metric, higher_is_better):\n",
    "    pivot = df.pivot_table(index=\"problem\", columns=\"framework\", values=metric, aggfunc=\"mean\")\n",
    "    pivot = pivot.dropna(axis=1, how=\"any\")\n",
    "    if pivot.shape[1] < 3:\n",
    "        print(\"Need at least 3 frameworks with full coverage for Friedman test.\")\n",
    "        return None, None, None, None\n",
    "    scores = pivot.to_numpy()\n",
    "    fried = friedman_test(scores, higher_is_better=higher_is_better)\n",
    "    wilc = pairwise_wilcoxon(scores, pivot.columns, higher_is_better=higher_is_better)\n",
    "    wilc_df = pd.DataFrame([w.__dict__ for w in wilc]).sort_values(\"p_value\")\n",
    "    wilc_df[\"p_holm\"] = holm_correction(wilc_df[\"p_value\"].to_numpy())\n",
    "\n",
    "    effects = []\n",
    "    names = list(pivot.columns)\n",
    "    for i in range(len(names)):\n",
    "        for j in range(i + 1, len(names)):\n",
    "            delta = cliffs_delta(scores[:, i], scores[:, j])\n",
    "            effects.append({\"algo_i\": names[i], \"algo_j\": names[j], \"cliffs_delta\": delta})\n",
    "    effects_df = pd.DataFrame(effects)\n",
    "    return pivot, fried, wilc_df, effects_df\n",
    "\n",
    "if not results_df.empty:\n",
    "    metric_specs = [\n",
    "        (\"hv_norm\", True),\n",
    "        (\"hv\", True),\n",
    "        (\"igd\", False),\n",
    "        (\"igd_plus\", False),\n",
    "        (\"epsilon_add\", False),\n",
    "    ]\n",
    "    for metric, higher_is_better in metric_specs:\n",
    "        if metric not in results_df.columns or results_df[metric].isna().all():\n",
    "            continue\n",
    "        pivot, fried, wilc_df, effects_df = stats_table(results_df, metric, higher_is_better)\n",
    "        if fried is None:\n",
    "            continue\n",
    "        print(f\"Metric: {metric} | Friedman p-value: {fried.p_value:.4g}\")\n",
    "        display(wilc_df.head())\n",
    "        display(effects_df)\n",
    "        if CD_STYLE == \"saes\":\n",
    "            plot_cd_saes_style(pivot.to_numpy(), pivot.columns, maximize=higher_is_better)\n",
    "        else:\n",
    "            plot_critical_distance(fried.avg_ranks, pivot.columns, n_problems=len(pivot), show=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "qot_md",
   "metadata": {},
   "source": [
    "## Quality over time and time-to-target (optional)\n",
    "\n",
    "This section runs a multi-budget sweep to approximate quality over time curves.\n",
    "Set RUN_QOT=True to enable.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "qot_run",
   "metadata": {},
   "outputs": [],
   "source": [
    "qot_df = pd.DataFrame()\n",
    "if RUN_QOT:\n",
    "    qot_results = []\n",
    "    for spec in PROBLEMS:\n",
    "        if spec[\"key\"] not in REF_FRONTS:\n",
    "            continue\n",
    "        ref = REF_FRONTS[spec[\"key\"]]\n",
    "        for framework in FRAMEWORKS:\n",
    "            runner = RUNNERS.get(framework)\n",
    "            if runner is None:\n",
    "                continue\n",
    "            for seed in QOT_SEEDS:\n",
    "                for frac in QOT_BUDGETS:\n",
    "                    max_evals = max(1, int(MAX_EVALS * frac))\n",
    "                    try:\n",
    "                        F, elapsed, peak, cpu_time, rss_mb, rss_delta = run_with_profile(\n",
    "                            runner,\n",
    "                            spec,\n",
    "                            seed,\n",
    "                            max_evals=max_evals,\n",
    "                            pop_size=POP_SIZE,\n",
    "                        )\n",
    "                    except Exception as exc:\n",
    "                        print(f\"QOT skip {framework} {spec['label']} seed {seed}: {exc}\")\n",
    "                        continue\n",
    "                    if F is None or len(F) == 0:\n",
    "                        continue\n",
    "                    metrics = compute_metrics(F, ref)\n",
    "                    qot_results.append(\n",
    "                        {\n",
    "                            \"framework\": framework,\n",
    "                            \"problem\": spec[\"label\"],\n",
    "                            \"seed\": seed,\n",
    "                            \"budget_frac\": frac,\n",
    "                            \"n_eval\": max_evals,\n",
    "                            \"time_s\": elapsed,\n",
    "                            \"hv\": metrics[\"hv\"],\n",
    "                            \"hv_norm\": metrics[\"hv_norm\"],\n",
    "                            \"igd\": metrics[\"igd\"],\n",
    "                        }\n",
    "                    )\n",
    "    qot_df = pd.DataFrame(qot_results)\n",
    "    qot_df.head()\n",
    "else:\n",
    "    print(\"Set RUN_QOT=True to run this section.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "qot_plot",
   "metadata": {},
   "outputs": [],
   "source": [
    "if RUN_QOT and not qot_df.empty:\n",
    "    metric = \"hv_norm\" if qot_df[\"hv_norm\"].notna().any() else \"hv\"\n",
    "    for problem in qot_df[\"problem\"].unique():\n",
    "        sub = qot_df[qot_df[\"problem\"] == problem]\n",
    "        fig, ax = plt.subplots(figsize=(7, 4))\n",
    "        for framework in sub[\"framework\"].unique():\n",
    "            group = (\n",
    "                sub[sub[\"framework\"] == framework]\n",
    "                .groupby(\"budget_frac\")\n",
    "                .agg(metric=(metric, \"mean\"), time_s=(\"time_s\", \"mean\"))\n",
    "                .sort_values(\"time_s\")\n",
    "            )\n",
    "            ax.plot(group[\"time_s\"], group[\"metric\"], marker=\"o\", label=framework)\n",
    "        ax.set_xlabel(\"Time (s)\")\n",
    "        ax.set_ylabel(metric)\n",
    "        ax.set_title(f\"Quality over time: {problem}\")\n",
    "        ax.legend()\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "    targets = {}\n",
    "    max_frac = max(QOT_BUDGETS)\n",
    "    for problem in qot_df[\"problem\"].unique():\n",
    "        full = qot_df[(qot_df[\"problem\"] == problem) & (qot_df[\"budget_frac\"] == max_frac)]\n",
    "        best = full.groupby(\"framework\")[metric].mean().max()\n",
    "        targets[problem] = 0.95 * best\n",
    "\n",
    "    ttt_rows = []\n",
    "    for (problem, framework), group in qot_df.groupby([\"problem\", \"framework\"]):\n",
    "        target = targets.get(problem, np.nan)\n",
    "        if np.isnan(target):\n",
    "            continue\n",
    "        group = group.sort_values(\"time_s\")\n",
    "        hits = group[group[metric] >= target]\n",
    "        ttt = hits[\"time_s\"].min() if not hits.empty else np.nan\n",
    "        ttt_rows.append({\"problem\": problem, \"framework\": framework, \"metric\": metric, \"target\": target, \"time_to_target_s\": ttt})\n",
    "\n",
    "    ttt_df = pd.DataFrame(ttt_rows)\n",
    "    ttt_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "scale_md",
   "metadata": {},
   "source": [
    "## Scalability sweep (n_var, n_obj, pop size)\n",
    "\n",
    "Set RUN_SCALING=True to execute. Default is VAMOS-only to keep runtime reasonable.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "scale_run",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaling_df = pd.DataFrame()\n",
    "if RUN_SCALING:\n",
    "    scaling_results = []\n",
    "    for n_obj in SCALING_N_OBJS:\n",
    "        for n_var in SCALING_N_VARS:\n",
    "            if n_var <= n_obj:\n",
    "                continue\n",
    "            spec = {\n",
    "                \"key\": \"dtlz2\",\n",
    "                \"label\": f\"DTLZ2-{n_var}v-{n_obj}o\",\n",
    "                \"n_var\": n_var,\n",
    "                \"n_obj\": n_obj,\n",
    "            }\n",
    "            for pop in SCALING_POP_SIZES:\n",
    "                for framework in SCALING_FRAMEWORKS:\n",
    "                    runner = RUNNERS.get(framework)\n",
    "                    if runner is None:\n",
    "                        continue\n",
    "                    try:\n",
    "                        F, elapsed, peak, cpu_time, rss_mb, rss_delta = run_with_profile(\n",
    "                            runner,\n",
    "                            spec,\n",
    "                            SCALING_SEED,\n",
    "                            max_evals=SCALING_MAX_EVALS,\n",
    "                            pop_size=pop,\n",
    "                        )\n",
    "                    except Exception as exc:\n",
    "                        print(f\"Scaling skip {framework} {spec['label']} pop {pop}: {exc}\")\n",
    "                        continue\n",
    "                    scaling_results.append(\n",
    "                        {\n",
    "                            \"framework\": framework,\n",
    "                            \"problem\": spec[\"label\"],\n",
    "                            \"n_var\": n_var,\n",
    "                            \"n_obj\": n_obj,\n",
    "                            \"pop_size\": pop,\n",
    "                            \"n_eval\": SCALING_MAX_EVALS,\n",
    "                            \"time_s\": elapsed,\n",
    "                            \"cpu_time_s\": cpu_time,\n",
    "                            \"mem_mb\": peak,\n",
    "                            \"rss_mb\": rss_mb,\n",
    "                        }\n",
    "                    )\n",
    "    scaling_df = pd.DataFrame(scaling_results)\n",
    "    scaling_df\n",
    "else:\n",
    "    print(\"Set RUN_SCALING=True to run this section.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "scale_plot",
   "metadata": {},
   "outputs": [],
   "source": [
    "if RUN_SCALING and not scaling_df.empty:\n",
    "    scaling_df = scaling_df.copy()\n",
    "    scaling_df[\"evals_per_sec\"] = scaling_df[\"n_eval\"] / scaling_df[\"time_s\"]\n",
    "\n",
    "    for framework in scaling_df[\"framework\"].unique():\n",
    "        sub = scaling_df[scaling_df[\"framework\"] == framework]\n",
    "        for n_obj in sorted(sub[\"n_obj\"].unique()):\n",
    "            sub_obj = sub[sub[\"n_obj\"] == n_obj]\n",
    "            pivot = sub_obj.pivot_table(index=\"n_var\", columns=\"pop_size\", values=\"time_s\", aggfunc=\"mean\")\n",
    "            ax = pivot.plot(kind=\"line\", marker=\"o\", figsize=(7, 4))\n",
    "            ax.set_title(f\"{framework} runtime scaling (n_obj={n_obj})\")\n",
    "            ax.set_xlabel(\"n_var\")\n",
    "            ax.set_ylabel(\"Time (s)\")\n",
    "            plt.tight_layout()\n",
    "            plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "perf_md",
   "metadata": {},
   "source": [
    "## Performance claims: vectorized vs baseline evaluation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "vectorized",
   "metadata": {},
   "outputs": [],
   "source": [
    "EVAL_SAMPLES = 5000\n",
    "perf_problem = ZDT1(n_var=30)\n",
    "rng = np.random.default_rng(0)\n",
    "X_eval = rng.uniform(perf_problem.xl, perf_problem.xu, size=(EVAL_SAMPLES, perf_problem.n_var))\n",
    "\n",
    "def eval_vectorized():\n",
    "    F = np.empty((X_eval.shape[0], perf_problem.n_obj))\n",
    "    perf_problem.evaluate(X_eval, {\"F\": F})\n",
    "    return F\n",
    "\n",
    "def eval_baseline():\n",
    "    F = np.empty((X_eval.shape[0], perf_problem.n_obj))\n",
    "    for i in range(X_eval.shape[0]):\n",
    "        perf_problem.evaluate(X_eval[i:i+1], {\"F\": F[i:i+1]})\n",
    "    return F\n",
    "\n",
    "_, vec_time, vec_mem, vec_cpu, vec_rss, vec_rss_delta = run_with_profile(lambda: eval_vectorized())\n",
    "_, base_time, base_mem, base_cpu, base_rss, base_rss_delta = run_with_profile(lambda: eval_baseline())\n",
    "\n",
    "pd.DataFrame(\n",
    "    [\n",
    "        {\n",
    "            \"mode\": \"vectorized\",\n",
    "            \"time_s\": vec_time,\n",
    "            \"cpu_time_s\": vec_cpu,\n",
    "            \"mem_mb\": vec_mem,\n",
    "            \"rss_mb\": vec_rss,\n",
    "            \"rss_mb_delta\": vec_rss_delta,\n",
    "        },\n",
    "        {\n",
    "            \"mode\": \"baseline_loop\",\n",
    "            \"time_s\": base_time,\n",
    "            \"cpu_time_s\": base_cpu,\n",
    "            \"mem_mb\": base_mem,\n",
    "            \"rss_mb\": base_rss,\n",
    "            \"rss_mb_delta\": base_rss_delta,\n",
    "        },\n",
    "    ]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "backend_md",
   "metadata": {},
   "source": [
    "## Performance claims: VAMOS backends (NumPy / Numba / MooCore)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "backend",
   "metadata": {},
   "outputs": [],
   "source": [
    "available_engines = []\n",
    "for name in KERNELS:\n",
    "    try:\n",
    "        resolve_kernel(name)\n",
    "        available_engines.append(name)\n",
    "    except Exception as exc:\n",
    "        print(f\"Skipping {name}: {exc}\")\n",
    "\n",
    "def run_backend(engine):\n",
    "    problem = ZDT1(n_var=30)\n",
    "    cfg = NSGAIIConfig.default(pop_size=POP_SIZE, n_var=problem.n_var, engine=engine)\n",
    "    return optimize(\n",
    "        OptimizeConfig(\n",
    "            problem=problem,\n",
    "            algorithm=\"nsgaii\",\n",
    "            algorithm_config=cfg,\n",
    "            termination=(\"n_eval\", MAX_EVALS),\n",
    "            seed=42,\n",
    "            engine=engine,\n",
    "        )\n",
    "    )\n",
    "\n",
    "backend_results = []\n",
    "for engine in available_engines:\n",
    "    if engine == \"numba\":\n",
    "        _ = run_backend(engine)  # warmup for JIT\n",
    "    _, elapsed, peak, cpu_time, rss_mb, rss_delta = run_with_profile(lambda e=engine: run_backend(e))\n",
    "    backend_results.append(\n",
    "        {\"engine\": engine, \"time_s\": elapsed, \"mem_mb\": peak, \"rss_mb\": rss_mb, \"cpu_time_s\": cpu_time}\n",
    "    )\n",
    "\n",
    "backend_df = pd.DataFrame(backend_results)\n",
    "print(\"\\n=== LaTeX Table ===\\n\")\n",
    "print(backend_df.to_latex(index=False, float_format=\"%.4f\", caption=\"Backend Performance Comparison\", label=\"tab:backend_perf\"))\n",
    "print(\"===================\\n\")\n",
    "backend_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "backend_plot",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not backend_df.empty and \"numpy\" in backend_df[\"engine\"].values:\n",
    "    numpy_time = backend_df.loc[backend_df[\"engine\"] == \"numpy\", \"time_s\"].iloc[0]\n",
    "    backend_df[\"speedup_vs_numpy\"] = numpy_time / backend_df[\"time_s\"]\n",
    "\n",
    "if not backend_df.empty:\n",
    "    fig, ax = plt.subplots(figsize=(8, 4))\n",
    "    ax.bar(backend_df[\"engine\"], backend_df[\"time_s\"], color=\"steelblue\")\n",
    "    ax.set_ylabel(\"Runtime (s)\")\n",
    "    ax.set_title(\"Backend runtime comparison\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "qot_viz_md",
   "metadata": {},
   "source": [
    "### QOT Visualization\n",
    "\n",
    "Visualizing the quality metrics over time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "qot_viz",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not qot_df.empty:\n",
    "    import seaborn as sns\n",
    "    sns.set_theme(style=\"darkgrid\")\n",
    "    \n",
    "    metrics_to_plot = [\"hv\", \"hv_norm\", \"igd\"]\n",
    "    for metric in metrics_to_plot:\n",
    "        if metric in qot_df.columns:\n",
    "            plt.figure(figsize=(10, 6))\n",
    "            sns.lineplot(\n",
    "                data=qot_df, \n",
    "                x=\"n_eval\", \n",
    "                y=metric, \n",
    "                hue=\"framework\", \n",
    "                style=\"problem\", \n",
    "                markers=True,\n",
    "                dashes=False\n",
    "            )\n",
    "            plt.title(f\"Quality over Time: {metric.upper()}\")\n",
    "            plt.tight_layout()\n",
    "            plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "scaling_md",
   "metadata": {},
   "source": [
    "## Scaling Analysis (optional)\n",
    "\n",
    "Benchmark runtime and memory usage as a function of problem scale (number of variables).\n",
    "Set RUN_SCALING=True to enable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "scaling_run",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaling_df = pd.DataFrame()\n",
    "if RUN_SCALING:\n",
    "    print(\"Running scaling analysis...\")\n",
    "    # Clean scaling specs - focus on ZDT1 for scaling variables\n",
    "    scaling_key = \"zdt1\"\n",
    "    \n",
    "    scaling_specs = []\n",
    "    # Scales: \n",
    "    for n in SCALING_N_VARS:\n",
    "        s = {\"key\": scaling_key, \"n_obj\": 2, \"n_var\": n, \"label\": f\"{scaling_key}_d{n}\"}\n",
    "        scaling_specs.append(s)\n",
    "        \n",
    "    scaling_results = []\n",
    "    for spec in scaling_specs:\n",
    "        problem_label = spec[\"label\"]\n",
    "        print(f\"  Scaling problem: {problem_label}\")\n",
    "        \n",
    "        for framework in SCALING_FRAMEWORKS:\n",
    "            runner = RUNNERS.get(framework)\n",
    "            if runner is None:\n",
    "                continue\n",
    "            \n",
    "            seed = SCALING_SEED\n",
    "            try:\n",
    "                # We care about time and memory here\n",
    "                F, elapsed, peak, cpu_time, rss_mb, rss_delta = run_with_profile(\n",
    "                    runner,\n",
    "                    spec,\n",
    "                    seed,\n",
    "                    max_evals=SCALING_MAX_EVALS,\n",
    "                    pop_size=POP_SIZE # Or use SCALING_POP_SIZES if we want to scale that too\n",
    "                )\n",
    "                \n",
    "                scaling_results.append({\n",
    "                    \"framework\": framework,\n",
    "                    \"n_var\": spec[\"n_var\"],\n",
    "                    \"time_s\": elapsed,\n",
    "                    \"peak_mem_mb\": peak,\n",
    "                    \"rss_mb\": rss_mb\n",
    "                })\n",
    "            except Exception as e:\n",
    "                print(f\"Scaling fail {framework} {problem_label}: {e}\")\n",
    "\n",
    "    scaling_df = pd.DataFrame(scaling_results)\n",
    "    if not scaling_df.empty:\n",
    "        display(scaling_df)\n",
    "        \n",
    "        # Plot Time Scaling\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        sns.lineplot(data=scaling_df, x=\"n_var\", y=\"time_s\", hue=\"framework\", marker=\"o\")\n",
    "        plt.title(\"Runtime Scaling (ZDT1)\")\n",
    "        plt.xlabel(\"Number of Variables\")\n",
    "        plt.ylabel(\"Time (s)\")\n",
    "        # plt.yscale(\"log\")\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        \n",
    "        # Plot Memory Scaling\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        sns.lineplot(data=scaling_df, x=\"n_var\", y=\"peak_mem_mb\", hue=\"framework\", marker=\"o\")\n",
    "        plt.title(\"Peak Memory Scaling (ZDT1)\")\n",
    "        plt.xlabel(\"Number of Variables\")\n",
    "        plt.ylabel(\"Peak Memory (MB)\")\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "else:\n",
    "    print(\"Set RUN_SCALING=True to run this section.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
