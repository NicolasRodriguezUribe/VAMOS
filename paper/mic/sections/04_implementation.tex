\section{Implementation and reproducibility}
\label{sec:implementation}

\subsection{Integration into NSGA-II}
The five-stage pipeline described in Section~\ref{sec:aos_overview} is implemented as a lightweight controller that wraps the standard NSGA-II loop.
At the beginning of each generation, the controller queries the bandit policy (Stage~2) and passes the selected arm index to the variation module.
During the generation, it records the number of offspring created by the selected arm.
After survivor selection, it computes reward components ($r_{\mathrm{surv}}$, $r_{\mathrm{nd}}$, and optionally $r_{\mathrm{hv}}$), updates the policy (Stage~5), and emits a trace row for logging.
The controller adds no additional objective evaluations; its overhead comes solely from bookkeeping and the policy update.

\subsection{Determinism}
To support reproducibility, we separate (a) the global run seed that drives variation and selection randomness from (b) an optional policy RNG seed that drives the stochastic policy components (e.g., $\varepsilon$-greedy exploration).
With fixed seeds, the operator-selection sequence and rewards are deterministic for a given configuration.

\subsection{Logging}
We log two types of artifacts for post-hoc analysis:
(i) a per-generation trace (generation index, selected operator, reward breakdown, and batch size), and
(ii) a summary table (number of pulls and mean reward per arm at the end of the run).
These logs enable inspection of when the policy switches operators, whether it locks into a single arm, and how reward signals evolve over time.

\subsection{Computational efficiency}
All experiments are executed within VAMOS, a vectorized Python framework for multiobjective optimization that leverages Numba JIT compilation to achieve near-native performance.
We compare its runtime against pymoo~\cite{pymoo} and jMetalPy~\cite{jmetalpy}, the two most widely adopted Python MOEA frameworks in recent literature.
DEAP~\cite{deap} and Platypus are deliberately excluded from this comparison: DEAP is a general-purpose evolutionary computation toolkit whose NSGA-II implementation prioritizes pedagogical clarity over computational efficiency, while Platypus has seen little active maintenance and has a substantially smaller adoption in the MOEA community.
Both frameworks ran more than one order of magnitude slower than pymoo on our benchmarks in preliminary tests, making them unsuitable comparison points for a performance evaluation; retaining them would also have multiplied the total experiment time by a factor incompatible with the publication timeline.
The comparison is therefore restricted to pymoo and jMetalPy, which represent the current state of the art in optimized Python MOEA implementations.

