"""
Generate HV summary tables for NSGA-II variants (steady-state and external archive).

Usage: python paper/17_update_variant_hv_tables_from_csv.py

Reads:
  - experiments/benchmark_paper_nsgaii_ss.csv
  - experiments/benchmark_paper_nsgaii_archive.csv

Writes:
  - paper/manuscript/frameworks_hv_nsgaii_ss.tex
  - paper/manuscript/frameworks_hv_nsgaii_archive.tex
"""

from __future__ import annotations

from pathlib import Path

import numpy as np
import pandas as pd

ROOT_DIR = Path(__file__).parent.parent
DATA_DIR = ROOT_DIR / "experiments"
MANUSCRIPT_DIR = Path(__file__).parent / "manuscript"

# Map framework names to display names for HV tables (use Numba as representative VAMOS backend)
VAMOS_BACKEND = "VAMOS (numba)"

TABLE_SPECS = {
    "nsgaii_ss": {
        "csv": DATA_DIR / "benchmark_paper_nsgaii_ss.csv",
        "out": MANUSCRIPT_DIR / "frameworks_hv_nsgaii_ss.tex",
        "label": "tab:frameworks_hv_nsgaii_ss",
        "caption": "NSGA-II (steady-state). Normalized hypervolume summary (median (IQR)) by problem family across frameworks (Platypus omitted: no steady-state API)",
    },
    "nsgaii_archive": {
        "csv": DATA_DIR / "benchmark_paper_nsgaii_archive.csv",
        "out": MANUSCRIPT_DIR / "frameworks_hv_nsgaii_archive.tex",
        "label": "tab:frameworks_hv_nsgaii_archive",
        "caption": "NSGA-II (ext.\\ archive). Normalized hypervolume summary (median (IQR)) by problem family across frameworks",
    },
}

# Framework display order (VAMOS first, then alphabetical competitors)
FRAMEWORK_ORDER = ["VAMOS", "pymoo", "jMetalPy", "DEAP", "Platypus"]


def get_family(problem: str) -> str:
    if problem.startswith("zdt"):
        return "ZDT"
    if problem.startswith("dtlz"):
        return "DTLZ"
    if problem.startswith("wfg"):
        return "WFG"
    return "Other"


def _normalize_fw(fw: str) -> str:
    """Collapse VAMOS backend variants into a single 'VAMOS' label, keeping the Numba backend."""
    if fw.startswith("VAMOS"):
        return fw  # Keep backend label for filtering
    return fw


def build_hv_summary(df: pd.DataFrame) -> pd.DataFrame:
    """Build a family-level HV summary: median (IQR) per framework per family."""
    # Keep only the primary VAMOS backend
    vamos_rows = df[df["framework"] == VAMOS_BACKEND].copy()
    vamos_rows["framework"] = "VAMOS"
    other_rows = df[~df["framework"].str.startswith("VAMOS")].copy()
    df_clean = pd.concat([vamos_rows, other_rows], ignore_index=True)

    df_clean["family"] = df_clean["problem"].apply(get_family)

    # Compute per-problem median HV across seeds
    per_problem = (
        df_clean.groupby(["framework", "problem", "family"])["hypervolume"]
        .median()
        .reset_index()
        .rename(columns={"hypervolume": "hv_median"})
    )

    # Compute family-level summary: median and IQR of per-problem medians
    rows = []
    for fw in FRAMEWORK_ORDER:
        fw_data = per_problem[per_problem["framework"] == fw]
        if fw_data.empty:
            continue
        row = {"Framework": fw}
        for family in ["ZDT", "DTLZ", "WFG"]:
            family_data = fw_data[fw_data["family"] == family]["hv_median"]
            if family_data.empty:
                row[family] = "---"
            else:
                med = family_data.median()
                iqr = family_data.quantile(0.75) - family_data.quantile(0.25)
                row[family] = f"{med:.3f} ({iqr:.3f})"
        # Overall: all per-problem medians
        all_medians = fw_data["hv_median"]
        med = all_medians.median()
        iqr = all_medians.quantile(0.75) - all_medians.quantile(0.25)
        row["Overall"] = f"{med:.3f} ({iqr:.3f})"
        rows.append(row)

    return pd.DataFrame(rows)


def make_latex_table(summary: pd.DataFrame, label: str, caption: str) -> str:
    """Generate a LaTeX table from the summary DataFrame."""
    lines = [
        f"% Auto-generated by {Path(__file__).name}",
        "",
        r"\begin{table*}[htbp]",
        r"\centering",
        f"\\caption{{{caption}}}",
        f"\\label{{{label}}}",
        r"\begin{tabular}{lcccc}",
        r"\toprule",
        r"\textbf{Framework} & \textbf{ZDT} & \textbf{DTLZ} & \textbf{WFG} & \textbf{Overall\textsuperscript{*}} \\",
        r"\midrule",
    ]

    for _, row in summary.iterrows():
        fw = row["Framework"]
        zdt = row.get("ZDT", "---")
        dtlz = row.get("DTLZ", "---")
        wfg = row.get("WFG", "---")
        overall = row.get("Overall", "---")
        lines.append(f"{fw} & {zdt} & {dtlz} & {wfg} & {overall} \\\\")

    lines.extend([
        r"\bottomrule",
        r"\end{tabular}",
        r"\end{table*}",
    ])

    return "\n".join(lines) + "\n"


def main() -> None:
    for algo_key, spec in TABLE_SPECS.items():
        csv_path = spec["csv"]
        if not csv_path.exists():
            print(f"  [SKIP] {csv_path} not found")
            continue

        print(f"Processing {algo_key}...")
        df = pd.read_csv(csv_path)
        summary = build_hv_summary(df)
        latex = make_latex_table(summary, spec["label"], spec["caption"])

        out_path = spec["out"]
        out_path.write_text(latex, encoding="utf-8")
        print(f"  Wrote {out_path}")
        print(summary.to_string(index=False))
        print()


if __name__ == "__main__":
    main()
